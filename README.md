# HSE PSB Hackathon

- [ВШЭ ПСБ.Хак](https://ai.hse.ru/hacks/psb24)
- Binary classification
- Tabular data
- AUC ROC metric
- [Not working leaderboard link](https://dsworks.ru/ru/champ/hse-2024-september)

## Final solution

A lot of feature engineering + [Autogluon](https://github.com/autogluon/autogluon)

## Report and thoughts in Russian

**Feature engineering:**

- Из временных колонок достали временные фичи такие как сезон, день, месяц, год, выходной день или нет и тд.
- Для временных колонок сделали разницу между ними. Разницу между временем заезда и временем бронирования, временем выезда и временем заезда. Каждую разницу измеряли в днях, часах и неделях.
- Из колонки способ оплаты надёргали бинарных фич по типу: была ли оплата картой, наличными. Фичи по типу какой банк: банк россии или мир и тд. Yandex pay или СБП
- Также наделали обычные фичи путём комбинирования различных колонок, например стоимость за ночь, гостей на номер, стоимость за одного гостя.
- Увидели, что предоплата сильно коррелирует с таргетом, накидали разных фич: (бинарная) была ли предоплата или нет, процент предоплаты от полной стоимости и тд.
- Определили основные периоды (связанные с политическими и социальными потрясениями), в которых существенно повышался процент отмен. Добавили это как ещё одну фичу.
- По итогу у нас 72 фичи для тренировки

**Final model:**

- [GitHub - autogluon/autogluon: Fast and Accurate ML in 3 Lines of Code](https://github.com/autogluon/autogluon) с presets='best_quality'. Автомл библиотека обучила различные модели от бустингов до нейросетей на предобработанных данных и взяла взвешенный ансамбль.
- Среди обученных моделей: CatBoost, XGBoost LightGBM, NeuralNetTorch, NeuralNetFastAI, Extra Trees.

**Second best model:**

- Так как в таргете дисбаланс классов использовали стратифицированный Kfold сплит cv=10.
- На каждом фолде обучали Catboost, а валидационную часть использовали для early stopping, чтобы избежать переобучения
- В качестве финального предсказания брали усреднённое предсказание по всем фолдам.

**What else was tried?**

- Предобработка данных
  - Добавляли данные погоды. Добавляли как просто погоду, так и недельную дельта изменения погоды
  - Очистка столбцов источник и категория номера и уменьшение классов в них
  - groupby по различным столбцам и агррегации mean, median, percentile 0.9 и 0.1
  - Проверяли гипотезу о наличии дубликатов бронирований. (Типо если чел случайно заказал не то, отменил и перезаказал заного.) Это тоже добавляли как фичу
- Фильтрация признаков
  - Фильтрация топ 15 на основании feature importance
  - Фильтрация с использованием Recursive feature elimination CV из sklearn
  - Фильтрация Recursive feature elimination из Catboost с shap values
- Модели
  - LightGBM
  - Random Forest
  - Extra Trees
  - Блендинг с одинаковыми весами 4х моделей LightGBM, Random Forest, Extra Trees, Catboost c подбором основных гиперпараметров для каждой модели с использованием Optuna на StratifiedKFold cv5 валидации
  - Различное количество фолдов кросс валидации 5, 10, 15, 20, 30
- Фишки
  - Так как в топ 10 всё решается на тысячных метрики AUC-ROC, пробовали по разному округлять значения вероятностей, чтобы улучшить скор
  - Псевдолейблинг: обучали на трейне, предсказывали тест и заного переобучали на train+test

**Main notes after lots of experimenting:**

- Колонка предоплаты имеет самую сильную корреляцию с таргетом.
- Так как в таргете дисбаланс классов часто использовали StratifiedKFold для валидации
- Скор на кросс валидации очень сильно коррелирует со скором на лидерборде
- Удаление признаков не влияет на метрику, поэтому оставляли все признаки. Удаление лишь влияет на скорость обучение и подбор гиперпараметров, но у нас с этим проблем не было.
- Все использованные модели имеют хороший скор как на лидерборде, так и на валидации. Блендинг моделей не даёт прирост, но при этом усложняет решение.
- Catboost с дефолтными параметрами и early stopping очень хорошо работает и не требует подбора гиперпараметров в отличие от LightGBM, Random Forest, Extra Trees
- Предсказание с помощью усреднения по фолдам лучше чем предсказание одной моделью, даже той, у которой лучший скор из всех фолдов.

**What else could be done?**

- Мы упёрлись в наш топ скор, который дал нам Catboost и не смогли его улучшить с помощью подбора гиперпараметров и использования других моделей.
- Значит скорее всего дело не в моделях, а в Feature Engineering. Возможно можно было придумать какие-то другие фичи или как то по-другому использовать существующие.
- Upd. В конце Autogluon всё таки докинул чуть-чуть сотых в AUC ROC
- Не использовали колонки время отмены и статус платежа
- DL модели? Simple NN, VAE?
- Стекинг?
