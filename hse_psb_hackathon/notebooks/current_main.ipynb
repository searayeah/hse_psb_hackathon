{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {},
  "cells": [
    {
      "metadata": {},
      "source": [
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import optuna\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from catboost import CatBoostClassifier\n",
        "from fisting import fit_catboost, fit_et, fit_lgbm, fit_rf, objective\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# feature selection again\n",
        "# feature selection again\n",
        "from sklearn.feature_selection import RFECV, SequentialFeatureSelector\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "\n",
        "df_train = pd.read_excel(\"train.xlsx\")\n",
        "df_test = pd.read_excel(\"test.xlsx\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "df_train"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>\u2116 \u0431\u0440\u043e\u043d\u0438</th>\n",
              "      <th>\u041d\u043e\u043c\u0435\u0440\u043e\u0432</th>\n",
              "      <th>\u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c</th>\n",
              "      <th>\u0412\u043d\u0435\u0441\u0435\u043d\u0430 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u0430</th>\n",
              "      <th>\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b</th>\n",
              "      <th>\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f</th>\n",
              "      <th>\u0414\u0430\u0442\u0430 \u043e\u0442\u043c\u0435\u043d\u044b</th>\n",
              "      <th>\u0417\u0430\u0435\u0437\u0434</th>\n",
              "      <th>\u041d\u043e\u0447\u0435\u0439</th>\n",
              "      <th>\u0412\u044b\u0435\u0437\u0434</th>\n",
              "      <th>\u0418\u0441\u0442\u043e\u0447\u043d\u0438\u043a</th>\n",
              "      <th>\u0421\u0442\u0430\u0442\u0443\u0441 \u0431\u0440\u043e\u043d\u0438</th>\n",
              "      <th>\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f \u043d\u043e\u043c\u0435\u0440\u0430</th>\n",
              "      <th>\u0413\u043e\u0441\u0442\u0435\u0439</th>\n",
              "      <th>\u0413\u043e\u0441\u0442\u0438\u043d\u0438\u0446\u0430</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>20230428-6634-194809261</td>\n",
              "      <td>1</td>\n",
              "      <td>25700.0</td>\n",
              "      <td>0</td>\n",
              "      <td>\u0412\u043d\u0435\u0448\u043d\u044f\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u043e\u043f\u043b\u0430\u0442\u044b</td>\n",
              "      <td>2023-04-20 20:37:30</td>\n",
              "      <td>2023-04-20 20:39:15</td>\n",
              "      <td>2023-04-28 15:00:00</td>\n",
              "      <td>3</td>\n",
              "      <td>2023-05-01 12:00:00</td>\n",
              "      <td>\u042f\u043d\u0434\u0435\u043a\u0441.\u041f\u0443\u0442\u0435\u0448\u0435\u0441\u0442\u0432\u0438\u044f</td>\n",
              "      <td>\u041e\u0442\u043c\u0435\u043d\u0430</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>20220711-6634-144460018</td>\n",
              "      <td>1</td>\n",
              "      <td>24800.0</td>\n",
              "      <td>12400</td>\n",
              "      <td>\u041e\u0442\u043b\u043e\u0436\u0435\u043d\u043d\u0430\u044f \u044d\u043b\u0435\u043a\u0442\u0440\u043e\u043d\u043d\u0430\u044f \u043e\u043f\u043b\u0430\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430...</td>\n",
              "      <td>2022-06-18 14:17:02</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2022-07-11 15:00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>2022-07-13 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>20221204-16563-171020423</td>\n",
              "      <td>1</td>\n",
              "      <td>25800.0</td>\n",
              "      <td>12900</td>\n",
              "      <td>\u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)</td>\n",
              "      <td>2022-11-14 22:59:30</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2022-12-04 15:00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>2022-12-06 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0443\u0434\u0438\u044f\u00bb</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>20230918-7491-223512699</td>\n",
              "      <td>1</td>\n",
              "      <td>10500.0</td>\n",
              "      <td>0</td>\n",
              "      <td>\u0412\u043d\u0435\u0448\u043d\u044f\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u043e\u043f\u043b\u0430\u0442\u044b (\u0421 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u043e\u0439)</td>\n",
              "      <td>2023-09-08 15:55:53</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2023-09-18 15:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-09-19 12:00:00</td>\n",
              "      <td>Bronevik.com(new)</td>\n",
              "      <td>\u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>20230529-6634-200121971</td>\n",
              "      <td>1</td>\n",
              "      <td>28690.0</td>\n",
              "      <td>28690</td>\n",
              "      <td>\u0421\u0438\u0441\u0442\u0435\u043c\u0430 \u0431\u044b\u0441\u0442\u0440\u044b\u0445 \u043f\u043b\u0430\u0442\u0435\u0436\u0435\u0439: \u042d\u043a\u0432\u0430\u0439\u0440\u0438\u043d\u0433 ComfortBoo...</td>\n",
              "      <td>2023-05-20 19:54:13</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2023-05-29 15:00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>2023-05-31 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u041b\u044e\u043a\u0441\u00bb</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26169</th>\n",
              "      <td>26169</td>\n",
              "      <td>20230310-7492-177993190</td>\n",
              "      <td>1</td>\n",
              "      <td>18240.0</td>\n",
              "      <td>9120</td>\n",
              "      <td>\u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)</td>\n",
              "      <td>2023-01-07 17:45:18</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2023-03-10 15:00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>2023-03-12 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26170</th>\n",
              "      <td>26170</td>\n",
              "      <td>20230625-16563-206126520</td>\n",
              "      <td>1</td>\n",
              "      <td>69600.0</td>\n",
              "      <td>23200</td>\n",
              "      <td>\u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)</td>\n",
              "      <td>2023-06-20 17:54:17</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2023-06-25 15:00:00</td>\n",
              "      <td>3</td>\n",
              "      <td>2023-06-28 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0443\u0434\u0438\u044f\u00bb</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26171</th>\n",
              "      <td>26171</td>\n",
              "      <td>20220624-7492-137587082</td>\n",
              "      <td>1</td>\n",
              "      <td>55600.0</td>\n",
              "      <td>13900</td>\n",
              "      <td>\u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)</td>\n",
              "      <td>2022-05-08 19:24:05</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2022-06-24 15:00:00</td>\n",
              "      <td>4</td>\n",
              "      <td>2022-06-28 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26172</th>\n",
              "      <td>26172</td>\n",
              "      <td>20220427-7491-125459150</td>\n",
              "      <td>1</td>\n",
              "      <td>6300.0</td>\n",
              "      <td>0</td>\n",
              "      <td>\u0413\u0430\u0440\u0430\u043d\u0442\u0438\u044f \u0431\u0430\u043d\u043a\u043e\u0432\u0441\u043a\u043e\u0439 \u043a\u0430\u0440\u0442\u043e\u0439</td>\n",
              "      <td>2022-02-19 09:55:50</td>\n",
              "      <td>2022-04-16 23:14:35</td>\n",
              "      <td>2022-04-27 15:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>2022-04-28 12:00:00</td>\n",
              "      <td>booking.com</td>\n",
              "      <td>\u041e\u0442\u043c\u0435\u043d\u0430</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26173</th>\n",
              "      <td>26173</td>\n",
              "      <td>20220816-6634-155783156</td>\n",
              "      <td>1</td>\n",
              "      <td>24600.0</td>\n",
              "      <td>24600</td>\n",
              "      <td>\u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)</td>\n",
              "      <td>2022-08-13 22:35:43</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2022-08-16 15:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>2022-08-17 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439</td>\n",
              "      <td>\u0410\u043f\u0430\u0440\u0442\u0430\u043c\u0435\u043d\u0442\u044b \u0441 2 \u0441\u043f\u0430\u043b\u044c\u043d\u044f\u043c\u0438 \u0441 \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u044b\u043c \u0432\u0445\u043e\u0434\u043e\u043c</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26174 rows \u00d7 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0                   \u2116 \u0431\u0440\u043e\u043d\u0438  \u041d\u043e\u043c\u0435\u0440\u043e\u0432  \u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c  \\\n",
              "0               0   20230428-6634-194809261        1    25700.0   \n",
              "1               1   20220711-6634-144460018        1    24800.0   \n",
              "2               2  20221204-16563-171020423        1    25800.0   \n",
              "3               3   20230918-7491-223512699        1    10500.0   \n",
              "4               4   20230529-6634-200121971        1    28690.0   \n",
              "...           ...                       ...      ...        ...   \n",
              "26169       26169   20230310-7492-177993190        1    18240.0   \n",
              "26170       26170  20230625-16563-206126520        1    69600.0   \n",
              "26171       26171   20220624-7492-137587082        1    55600.0   \n",
              "26172       26172   20220427-7491-125459150        1     6300.0   \n",
              "26173       26173   20220816-6634-155783156        1    24600.0   \n",
              "\n",
              "       \u0412\u043d\u0435\u0441\u0435\u043d\u0430 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u0430                                      \u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b  \\\n",
              "0                       0                             \u0412\u043d\u0435\u0448\u043d\u044f\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u043e\u043f\u043b\u0430\u0442\u044b   \n",
              "1                   12400  \u041e\u0442\u043b\u043e\u0436\u0435\u043d\u043d\u0430\u044f \u044d\u043b\u0435\u043a\u0442\u0440\u043e\u043d\u043d\u0430\u044f \u043e\u043f\u043b\u0430\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430...   \n",
              "2                   12900             \u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)   \n",
              "3                       0             \u0412\u043d\u0435\u0448\u043d\u044f\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u043e\u043f\u043b\u0430\u0442\u044b (\u0421 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u043e\u0439)   \n",
              "4                   28690  \u0421\u0438\u0441\u0442\u0435\u043c\u0430 \u0431\u044b\u0441\u0442\u0440\u044b\u0445 \u043f\u043b\u0430\u0442\u0435\u0436\u0435\u0439: \u042d\u043a\u0432\u0430\u0439\u0440\u0438\u043d\u0433 ComfortBoo...   \n",
              "...                   ...                                                ...   \n",
              "26169                9120             \u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)   \n",
              "26170               23200             \u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)   \n",
              "26171               13900             \u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)   \n",
              "26172                   0                         \u0413\u0430\u0440\u0430\u043d\u0442\u0438\u044f \u0431\u0430\u043d\u043a\u043e\u0432\u0441\u043a\u043e\u0439 \u043a\u0430\u0440\u0442\u043e\u0439   \n",
              "26173               24600             \u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)   \n",
              "\n",
              "        \u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f         \u0414\u0430\u0442\u0430 \u043e\u0442\u043c\u0435\u043d\u044b               \u0417\u0430\u0435\u0437\u0434  \u041d\u043e\u0447\u0435\u0439  \\\n",
              "0     2023-04-20 20:37:30 2023-04-20 20:39:15 2023-04-28 15:00:00      3   \n",
              "1     2022-06-18 14:17:02                 NaT 2022-07-11 15:00:00      2   \n",
              "2     2022-11-14 22:59:30                 NaT 2022-12-04 15:00:00      2   \n",
              "3     2023-09-08 15:55:53                 NaT 2023-09-18 15:00:00      1   \n",
              "4     2023-05-20 19:54:13                 NaT 2023-05-29 15:00:00      2   \n",
              "...                   ...                 ...                 ...    ...   \n",
              "26169 2023-01-07 17:45:18                 NaT 2023-03-10 15:00:00      2   \n",
              "26170 2023-06-20 17:54:17                 NaT 2023-06-25 15:00:00      3   \n",
              "26171 2022-05-08 19:24:05                 NaT 2022-06-24 15:00:00      4   \n",
              "26172 2022-02-19 09:55:50 2022-04-16 23:14:35 2022-04-27 15:00:00      1   \n",
              "26173 2022-08-13 22:35:43                 NaT 2022-08-16 15:00:00      1   \n",
              "\n",
              "                    \u0412\u044b\u0435\u0437\u0434            \u0418\u0441\u0442\u043e\u0447\u043d\u0438\u043a \u0421\u0442\u0430\u0442\u0443\u0441 \u0431\u0440\u043e\u043d\u0438  \\\n",
              "0     2023-05-01 12:00:00  \u042f\u043d\u0434\u0435\u043a\u0441.\u041f\u0443\u0442\u0435\u0448\u0435\u0441\u0442\u0432\u0438\u044f       \u041e\u0442\u043c\u0435\u043d\u0430   \n",
              "1     2022-07-13 12:00:00    \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442     \u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439   \n",
              "2     2022-12-06 12:00:00    \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442     \u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439   \n",
              "3     2023-09-19 12:00:00   Bronevik.com(new)     \u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439   \n",
              "4     2023-05-31 12:00:00    \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442     \u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439   \n",
              "...                   ...                 ...          ...   \n",
              "26169 2023-03-12 12:00:00    \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442     \u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439   \n",
              "26170 2023-06-28 12:00:00    \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442     \u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439   \n",
              "26171 2022-06-28 12:00:00    \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442     \u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439   \n",
              "26172 2022-04-28 12:00:00         booking.com       \u041e\u0442\u043c\u0435\u043d\u0430   \n",
              "26173 2022-08-17 12:00:00    \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442     \u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439   \n",
              "\n",
              "                                   \u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f \u043d\u043e\u043c\u0435\u0440\u0430  \u0413\u043e\u0441\u0442\u0435\u0439  \u0413\u043e\u0441\u0442\u0438\u043d\u0438\u0446\u0430  \n",
              "0                                  \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb       2          1  \n",
              "1                                  \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb       2          1  \n",
              "2                                    \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0443\u0434\u0438\u044f\u00bb       2          4  \n",
              "3                                  \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb       1          3  \n",
              "4                                      \u041d\u043e\u043c\u0435\u0440 \u00ab\u041b\u044e\u043a\u0441\u00bb       4          1  \n",
              "...                                             ...     ...        ...  \n",
              "26169                              \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb       2          2  \n",
              "26170                                \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0443\u0434\u0438\u044f\u00bb       3          4  \n",
              "26171                              \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb       2          2  \n",
              "26172                              \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb       2          3  \n",
              "26173  \u0410\u043f\u0430\u0440\u0442\u0430\u043c\u0435\u043d\u0442\u044b \u0441 2 \u0441\u043f\u0430\u043b\u044c\u043d\u044f\u043c\u0438 \u0441 \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u044b\u043c \u0432\u0445\u043e\u0434\u043e\u043c       3          1  \n",
              "\n",
              "[26174 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "def prepare_df(df):\n",
        "    df = df.copy()\n",
        "    df = df.drop([\"Unnamed: 0\", \"\u2116 \u0431\u0440\u043e\u043d\u0438\"], axis=1)\n",
        "    df[\"\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f\"] = pd.to_datetime(df[\"\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f\"])\n",
        "    df[\"\u0417\u0430\u0435\u0437\u0434\"] = pd.to_datetime(df[\"\u0417\u0430\u0435\u0437\u0434\"])\n",
        "    df[\"\u0412\u044b\u0435\u0437\u0434\"] = pd.to_datetime(df[\"\u0412\u044b\u0435\u0437\u0434\"])\n",
        "    return df\n",
        "\n",
        "\n",
        "def create_date_features(df, prefix):\n",
        "    df = df.copy()\n",
        "    df[prefix + \"_month\"] = df[prefix].dt.month.astype(\"int8\")\n",
        "    df[prefix + \"_day_of_month\"] = df[prefix].dt.day.astype(\"int8\")\n",
        "    df[prefix + \"_day_of_year\"] = df[prefix].dt.dayofyear.astype(\"int16\")\n",
        "    df[prefix + \"_week_of_month\"] = (\n",
        "        df[prefix].apply(lambda d: (d.day - 1) // 7 + 1)\n",
        "    ).astype(\"int8\")\n",
        "    df[prefix + \"_week_of_year\"] = (df[prefix].dt.isocalendar().week).astype(\"int8\")\n",
        "    df[prefix + \"_day_of_week\"] = (df[prefix].dt.dayofweek + 1).astype(\"int8\")\n",
        "    df[prefix + \"_year\"] = df[prefix].dt.year.astype(\"int32\")\n",
        "    df[prefix + \"_is_wknd\"] = (df[prefix].dt.weekday // 4).astype(\"int8\")\n",
        "    df[prefix + \"_season\"] = np.where(df[prefix + \"_month\"].isin([12, 1, 2]), 0, 1)\n",
        "    df[prefix + \"_season\"] = np.where(\n",
        "        df[prefix + \"_month\"].isin([6, 7, 8]), 2, df[prefix + \"_season\"]\n",
        "    )\n",
        "    df[prefix + \"_season\"] = pd.Series(\n",
        "        np.where(df[prefix + \"_month\"].isin([9, 10, 11]), 3, df[prefix + \"_season\"])\n",
        "    ).astype(\"int8\")\n",
        "    return df\n",
        "\n",
        "\n",
        "def create_diff_features(df, prefix1, prefix2):\n",
        "    df = df.copy()\n",
        "    df[prefix1 + \"_\" + prefix2 + \"_diff_in_days\"] = (df[prefix1] - df[prefix2]).dt.days\n",
        "    df[prefix1 + \"_\" + prefix2 + \"_diff_in_weeks\"] = (\n",
        "        df[prefix1 + \"_\" + prefix2 + \"_diff_in_days\"] / 7\n",
        "    )\n",
        "    df[prefix1 + \"_\" + prefix2 + \"_diff_in_hours\"] = (\n",
        "        df[prefix1] - df[prefix2]\n",
        "    ).dt.total_seconds() / 3600\n",
        "    return df\n",
        "\n",
        "\n",
        "def create_payment_method_features(df):\n",
        "    df = df.copy()\n",
        "    df[\"SberPay\"] = df[\"\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b\"].apply(lambda x: int(\"SberPay\" in x))\n",
        "    df[\"Yandex Pay\"] = df[\"\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b\"].apply(lambda x: int(\"Yandex Pay\" in x))\n",
        "    df[\"\u041c\u0418\u0420\"] = df[\"\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b\"].apply(lambda x: int(\"\u041c\u0418\u0420\" in x))\n",
        "    df[\"ComfortBooking\"] = df[\"\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b\"].apply(lambda x: int(\"ComfortBooking\" in x))\n",
        "    df[\"TravelLine Pro\"] = df[\"\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b\"].apply(lambda x: int(\"TravelLine Pro\" in x))\n",
        "    df[\"\u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f\"] = df[\"\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b\"].apply(lambda x: int(\"\u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f\" in x))\n",
        "    df[\"\u0412\u043d\u0435\u0448\u043d\u044f\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u043e\u043f\u043b\u0430\u0442\u044b\"] = df[\"\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b\"].apply(\n",
        "        lambda x: int(\"\u0412\u043d\u0435\u0448\u043d\u044f\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u043e\u043f\u043b\u0430\u0442\u044b\" in x)\n",
        "    )\n",
        "    df[\"\u0411\u0430\u043d\u043a\u043e\u0432\u0441\u043a\u0430\u044f \u043a\u0430\u0440\u0442\u0430\"] = df[\"\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b\"].apply(\n",
        "        lambda x: int(\n",
        "            \"\u0411\u0430\u043d\u043a\u043e\u0432\u0441\u043a\u0430\u044f \u043a\u0430\u0440\u0442\u0430\" in x\n",
        "            or \"\u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430\".lower() in x.lower()\n",
        "            or \"\u0431\u0430\u043d\u043a\u043e\u0432\u0441\u043a\u043e\u0439 \u043a\u0430\u0440\u0442\u043e\u0439\".lower() in x.lower()\n",
        "        )\n",
        "    )\n",
        "    df[\"\u041e\u043f\u043b\u0430\u0442\u0430 \u043d\u0430\u043b\u0438\u0447\u043d\u044b\u043c\u0438\"] = df[\"\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b\"].apply(\n",
        "        lambda x: int(\"\u041e\u043f\u043b\u0430\u0442\u0430 \u043d\u0430\u043b\u0438\u0447\u043d\u044b\u043c\u0438\" in x)\n",
        "    )\n",
        "    df[\"\u0421 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u043e\u0439\"] = df[\"\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b\"].apply(lambda x: int(\"\u0421 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u043e\u0439\" in x))\n",
        "    df[\"\u0421\u0411\u041f\"] = df[\"\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b\"].apply(lambda x: int(\"\u0421\u0438\u0441\u0442\u0435\u043c\u0430 \u0431\u044b\u0441\u0442\u0440\u044b\u0445 \u043f\u043b\u0430\u0442\u0435\u0436\u0435\u0439\" in x))\n",
        "\n",
        "    df[\"\u041e\u0442\u043b\u043e\u0436\u0435\u043d\u043d\u0430\u044f \u044d\u043b\u0435\u043a\u0442\u0440\u043e\u043d\u043d\u0430\u044f \u043e\u043f\u043b\u0430\u0442\u0430\"] = df[\"\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b\"].apply(\n",
        "        lambda x: int(\"\u041e\u0442\u043b\u043e\u0436\u0435\u043d\u043d\u0430\u044f \u044d\u043b\u0435\u043a\u0442\u0440\u043e\u043d\u043d\u0430\u044f \u043e\u043f\u043b\u0430\u0442\u0430\" in x)\n",
        "    )\n",
        "\n",
        "    df[\"\u0413\u0430\u0440\u0430\u043d\u0442\u0438\u044f \u0431\u0430\u043d\u043a\u043e\u0432\u0441\u043a\u043e\u0439 \u043a\u0430\u0440\u0442\u043e\u0439\"] = df[\"\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b\"].apply(\n",
        "        lambda x: int(\"\u0413\u0430\u0440\u0430\u043d\u0442\u0438\u044f \u0431\u0430\u043d\u043a\u043e\u0432\u0441\u043a\u043e\u0439 \u043a\u0430\u0440\u0442\u043e\u0439\" in x)\n",
        "    )\n",
        "\n",
        "    df[\"\u041f\u0440\u0438 \u0437\u0430\u0441\u0435\u043b\u0435\u043d\u0438\u0438\"] = df[\"\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b\"].apply(lambda x: int(\"\u041f\u0440\u0438 \u0437\u0430\u0441\u0435\u043b\u0435\u043d\u0438\u0438\" in x))\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def clear_source_column(text):\n",
        "    # good\n",
        "    mapping = [\n",
        "        \"\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442\",\n",
        "        \"\u0411\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0438\u0437 \u044d\u043a\u0441\u0442\u0440\u0430\u043d\u0435\u0442\u0430\",\n",
        "        \"\u042f\u043d\u0434\u0435\u043a\u0441.\u041f\u0443\u0442\u0435\u0448\u0435\u0441\u0442\u0432\u0438\u044f\",\n",
        "        \"ostrovok\",\n",
        "        \"booking\",\n",
        "        \"\u041f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0430 \u043b\u043e\u044f\u043b\u044c\u043d\u043e\u0441\u0442\u0438\",\n",
        "        \"Bronevik\",\n",
        "        \"OneTwoTrip\",\n",
        "    ]\n",
        "\n",
        "    for map_ in mapping:\n",
        "        if map_.lower() in text.lower():\n",
        "            return map_\n",
        "    return \"other\"\n",
        "\n",
        "\n",
        "def clear_category(text):\n",
        "    # good\n",
        "    if \"\\n\" in text:\n",
        "        text = text.split(\"\\n\")\n",
        "        text = text[0]\n",
        "    text = text.strip(\"1. \")\n",
        "    return text"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "def preprocess_df(df):\n",
        "    df = df.copy()\n",
        "    df = prepare_df(df)\n",
        "    df = create_date_features(df, \"\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f\")\n",
        "    df = create_date_features(df, \"\u0417\u0430\u0435\u0437\u0434\")\n",
        "    df = create_date_features(df, \"\u0412\u044b\u0435\u0437\u0434\")\n",
        "    df = create_diff_features(df, \"\u0417\u0430\u0435\u0437\u0434\", \"\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f\")\n",
        "    df = create_diff_features(df, \"\u0412\u044b\u0435\u0437\u0434\", \"\u0417\u0430\u0435\u0437\u0434\")\n",
        "\n",
        "    df = create_payment_method_features(df)\n",
        "\n",
        "    df[\"\u0418\u0441\u0442\u043e\u0447\u043d\u0438\u043a\"] = df[\"\u0418\u0441\u0442\u043e\u0447\u043d\u0438\u043a\"].apply(clear_source_column)\n",
        "\n",
        "    df[\"\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f multiple selection\"] = df[\"\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f \u043d\u043e\u043c\u0435\u0440\u0430\"].apply(\n",
        "        lambda x: int(\"\\n\" in x)\n",
        "    )\n",
        "\n",
        "    df[\"\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f \u043d\u043e\u043c\u0435\u0440\u0430\"] = df[\"\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f \u043d\u043e\u043c\u0435\u0440\u0430\"].apply(clear_category)\n",
        "\n",
        "    # other features\n",
        "\n",
        "    df[\"\u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u0437\u0430 \u043d\u043e\u0447\u044c\"] = df[\"\u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c\"] / df[\"\u041d\u043e\u0447\u0435\u0439\"]\n",
        "    df[\"\u0412\u043d\u0435\u0441\u0435\u043d\u0430 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u0430 binary\"] = df.apply(\n",
        "        lambda x: int(x[\"\u0412\u043d\u0435\u0441\u0435\u043d\u0430 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u0430\"] != 0), axis=1\n",
        "    )\n",
        "\n",
        "    df[\"\u041f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u0430 \u0443\u043c\u043d\u043e\u0436\u0435\u043d\u043d\u0430\u044f \u043d\u0430 \u0432\u0440\u0435\u043c\u044f \u0434\u043e \u043f\u0440\u0438\u0431\u044b\u0442\u0438\u044f\"] = (\n",
        "        df[\"\u0412\u043d\u0435\u0441\u0435\u043d\u0430 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u0430\"] * df[\"\u0417\u0430\u0435\u0437\u0434_\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f_diff_in_days\"]\n",
        "    )\n",
        "\n",
        "    df[\"\u041f\u0440\u043e\u0446\u0435\u043d\u0442 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u0430 \u043e\u0442 \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u0438\"] = df[\"\u0412\u043d\u0435\u0441\u0435\u043d\u0430 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u0430\"] / df[\"\u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c\"]\n",
        "    df[\"\u0413\u043e\u0441\u0442\u0435\u0439 \u043d\u0430 \u043d\u043e\u043c\u0435\u0440\"] = df[\"\u0413\u043e\u0441\u0442\u0435\u0439\"] / df[\"\u041d\u043e\u043c\u0435\u0440\u043e\u0432\"]\n",
        "\n",
        "    df[\"\u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u043d\u0430 \u0433\u043e\u0441\u0442\u044f\"] = df[\"\u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c\"] / df[\"\u0413\u043e\u0441\u0442\u0435\u0439\"]\n",
        "    df[\"\u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u0437\u0430 \u043d\u043e\u043c\u0435\u0440\"] = df[\"\u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c\"] / df[\"\u041d\u043e\u043c\u0435\u0440\u043e\u0432\"]\n",
        "    df[\"\u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u0437\u0430 \u043d\u043e\u0447\u044c 1 \u043d\u043e\u043c\u0435\u0440\"] = df[\"\u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c\"] / df[\"\u041d\u043e\u0447\u0435\u0439\"] / df[\"\u041d\u043e\u043c\u0435\u0440\u043e\u0432\"]\n",
        "    df[\"\u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u0437\u0430 \u043d\u043e\u0447\u044c 1 \u0433\u043e\u0441\u0442\u044f\"] = df[\"\u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c\"] / df[\"\u041d\u043e\u0447\u0435\u0439\"] / df[\"\u0413\u043e\u0441\u0442\u0435\u0439\"]\n",
        "    df[\"\u0413\u043e\u0441\u0442\u0435\u0439 \u043d\u0430 \u043d\u043e\u043c\u0435\u0440\"] = df[\"\u0413\u043e\u0441\u0442\u0435\u0439\"] / df[\"\u041d\u043e\u043c\u0435\u0440\u043e\u0432\"]\n",
        "    df[\"\u0411\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0443\u0442\u0440\u043e\u043c\"] = df[\"\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f\"].apply(\n",
        "        lambda x: (\n",
        "            1\n",
        "            if x.time() >= pd.Timestamp(\"05:00:00\").time()\n",
        "            and x.time() < pd.Timestamp(\"11:00:00\").time()\n",
        "            else 0\n",
        "        )\n",
        "    )\n",
        "    df[\"\u0411\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0432\u0435\u0447\u0435\u0440\u043e\u043c\"] = df[\"\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f\"].apply(\n",
        "        lambda x: (\n",
        "            1\n",
        "            if x.time() >= pd.Timestamp(\"17:00:00\").time()\n",
        "            and x.time() < pd.Timestamp(\"23:00:00\").time()\n",
        "            else 0\n",
        "        )\n",
        "    )\n",
        "    df[\"\u0411\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u043d\u043e\u0447\u044c\u044e\"] = df[\"\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f\"].apply(\n",
        "        lambda x: (\n",
        "            1\n",
        "            if x.time() >= pd.Timestamp(\"23:00:00\").time()\n",
        "            or x.time() < pd.Timestamp(\"05:00:00\").time()\n",
        "            else 0\n",
        "        )\n",
        "    )\n",
        "    return df"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "df_train = preprocess_df(df_train)\n",
        "df_test = preprocess_df(df_test)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# drops\n",
        "df_train = df_train.drop([\"\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f\", \"\u0417\u0430\u0435\u0437\u0434\", \"\u0412\u044b\u0435\u0437\u0434\"], axis=1)\n",
        "df_test = df_test.drop([\"\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f\", \"\u0417\u0430\u0435\u0437\u0434\", \"\u0412\u044b\u0435\u0437\u0434\"], axis=1)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "df_train[\"target\"] = df_train[\"\u0414\u0430\u0442\u0430 \u043e\u0442\u043c\u0435\u043d\u044b\"].apply(lambda x: int(pd.notna(x)))\n",
        "df_train = df_train.drop([\"\u0414\u0430\u0442\u0430 \u043e\u0442\u043c\u0435\u043d\u044b\", \"\u0421\u0442\u0430\u0442\u0443\u0441 \u0431\u0440\u043e\u043d\u0438\"], axis=1)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "X_train = df_train.drop(\"target\", axis=1)\n",
        "y_train = df_train[\"target\"]"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# for forests\n",
        "encoder = OneHotEncoder(drop=\"first\", sparse_output=False)\n",
        "cat_columns = X_train.select_dtypes(include=[\"object\"]).columns\n",
        "X_train_forest = pd.concat(\n",
        "    [\n",
        "        X_train.drop(cat_columns, axis=1),\n",
        "        pd.DataFrame(\n",
        "            encoder.fit_transform(X_train[cat_columns]),\n",
        "            columns=encoder.get_feature_names_out(),\n",
        "        ),\n",
        "    ],\n",
        "    axis=1,\n",
        ")\n",
        "df_test_forest = pd.concat(\n",
        "    [\n",
        "        df_test.drop(cat_columns, axis=1),\n",
        "        pd.DataFrame(\n",
        "            encoder.transform(df_test[cat_columns]),\n",
        "            columns=encoder.get_feature_names_out(),\n",
        "        ),\n",
        "    ],\n",
        "    axis=1,\n",
        ")\n",
        "\n",
        "# for lgbm\n",
        "X_train_lgbm = X_train.copy()\n",
        "df_test_lgbm = df_test.copy()\n",
        "for cat in cat_columns:\n",
        "    X_train_lgbm[cat] = X_train_lgbm[cat].astype(\"category\")\n",
        "    df_test_lgbm[cat] = df_test_lgbm[cat].astype(\"category\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "SEARCH_BEST_PARAMS = True\n",
        "N_TRIALS = 30\n",
        "CAT_FEATURES = [\"\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b\", \"\u0418\u0441\u0442\u043e\u0447\u043d\u0438\u043a\", \"\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f \u043d\u043e\u043c\u0435\u0440\u0430\"]\n",
        "RANDOM_SEED = 42\n",
        "EVAL_METRIC = \"AUC\"\n",
        "EARLY_STOPPING = 50"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "selector_seq = SequentialFeatureSelector(\n",
        "    CatBoostClassifier(\n",
        "        verbose=0,\n",
        "        iterations=300,\n",
        "    ),\n",
        "    n_features_to_select=15,\n",
        "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=0),\n",
        "    scoring=\"roc_auc\",\n",
        "    n_jobs=-1,\n",
        "    # without early stopping, cannot pass val set\n",
        ")\n",
        "\n",
        "selector_seq = selector_seq.fit(X_train_forest, y_train)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/seara/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
            "1 fits failed out of a total of 5.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/seara/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/home/seara/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/catboost/core.py\", line 5220, in fit\n",
            "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
            "  File \"/home/seara/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/catboost/core.py\", line 2400, in _fit\n",
            "    self._train(\n",
            "  File \"/home/seara/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/catboost/core.py\", line 1780, in _train\n",
            "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
            "  File \"_catboost.pyx\", line 4833, in _catboost._CatBoost._train\n",
            "  File \"_catboost.pyx\", line 4882, in _catboost._CatBoost._train\n",
            "_catboost.CatBoostError: /src/catboost/catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/home/seara/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:540: FitFailedWarning: \n",
            "1 fits failed out of a total of 5.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/seara/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/home/seara/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/catboost/core.py\", line 5220, in fit\n",
            "    self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n",
            "  File \"/home/seara/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/catboost/core.py\", line 2400, in _fit\n",
            "    self._train(\n",
            "  File \"/home/seara/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/catboost/core.py\", line 1780, in _train\n",
            "    self._object._train(train_pool, test_pool, params, allow_clear_pool, init_model._object if init_model else None)\n",
            "  File \"_catboost.pyx\", line 4833, in _catboost._CatBoost._train\n",
            "  File \"_catboost.pyx\", line 4882, in _catboost._CatBoost._train\n",
            "_catboost.CatBoostError: /src/catboost/catboost/libs/data/quantization.cpp:2420: All features are either constant or ignored.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[27], line 16\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RFECV, SequentialFeatureSelector\n\u001b[1;32m      4\u001b[0m selector_seq \u001b[38;5;241m=\u001b[39m SequentialFeatureSelector(\n\u001b[1;32m      5\u001b[0m     CatBoostClassifier(\n\u001b[1;32m      6\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# without early stopping, cannot pass val set\u001b[39;00m\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m selector_seq \u001b[38;5;241m=\u001b[39m \u001b[43mselector_seq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_forest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/sklearn/feature_selection/_sequential.py:255\u001b[0m, in \u001b[0;36mSequentialFeatureSelector.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    253\u001b[0m is_auto_select \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_to_select \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iterations):\n\u001b[0;32m--> 255\u001b[0m     new_feature_idx, new_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_best_new_feature_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcloned_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_mask\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_auto_select \u001b[38;5;129;01mand\u001b[39;00m ((new_score \u001b[38;5;241m-\u001b[39m old_score) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol):\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/sklearn/feature_selection/_sequential.py:286\u001b[0m, in \u001b[0;36mSequentialFeatureSelector._get_best_new_feature_score\u001b[0;34m(self, estimator, X, y, cv, current_mask)\u001b[0m\n\u001b[1;32m    284\u001b[0m         candidate_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mcandidate_mask\n\u001b[1;32m    285\u001b[0m     X_new \u001b[38;5;241m=\u001b[39m X[:, candidate_mask]\n\u001b[0;32m--> 286\u001b[0m     scores[feature_idx] \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_new\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m    294\u001b[0m new_feature_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(scores, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m feature_idx: scores[feature_idx])\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_feature_idx, scores[new_feature_idx]\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:712\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    710\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 712\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:423\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    422\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 423\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    445\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "selector = RFECV(\n",
        "    CatBoostClassifier(\n",
        "        verbose=0,\n",
        "        # eval_metric=EVAL_METRIC,\n",
        "        # early_stopping_rounds=EARLY_STOPPING,\n",
        "    ),\n",
        "    step=1,\n",
        "    min_features_to_select=15,\n",
        "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=0),\n",
        "    scoring=\"roc_auc\",\n",
        "    # without early stopping, cannot pass val set\n",
        ")\n",
        "\n",
        "selector = selector.fit(X_train_forest, y_train)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "X_train_forest.columns[selector.support_]"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['\u041d\u043e\u043c\u0435\u0440\u043e\u0432', '\u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c', '\u0412\u043d\u0435\u0441\u0435\u043d\u0430 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u0430', '\u041d\u043e\u0447\u0435\u0439', '\u0413\u043e\u0441\u0442\u0435\u0439',\n",
              "       '\u0413\u043e\u0441\u0442\u0438\u043d\u0438\u0446\u0430', '\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f_month',\n",
              "       '\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f_day_of_month', '\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f_day_of_year',\n",
              "       '\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f_week_of_month', '\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f_week_of_year',\n",
              "       '\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f_day_of_week', '\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f_year',\n",
              "       '\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f_is_wknd', '\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f_season', '\u0417\u0430\u0435\u0437\u0434_month',\n",
              "       '\u0417\u0430\u0435\u0437\u0434_day_of_month', '\u0417\u0430\u0435\u0437\u0434_day_of_year', '\u0417\u0430\u0435\u0437\u0434_week_of_month',\n",
              "       '\u0417\u0430\u0435\u0437\u0434_week_of_year', '\u0417\u0430\u0435\u0437\u0434_day_of_week', '\u0417\u0430\u0435\u0437\u0434_year',\n",
              "       '\u0417\u0430\u0435\u0437\u0434_is_wknd', '\u0417\u0430\u0435\u0437\u0434_season', '\u0412\u044b\u0435\u0437\u0434_month', '\u0412\u044b\u0435\u0437\u0434_day_of_month',\n",
              "       '\u0412\u044b\u0435\u0437\u0434_day_of_year', '\u0412\u044b\u0435\u0437\u0434_week_of_month', '\u0412\u044b\u0435\u0437\u0434_week_of_year',\n",
              "       '\u0412\u044b\u0435\u0437\u0434_day_of_week', '\u0412\u044b\u0435\u0437\u0434_year', '\u0412\u044b\u0435\u0437\u0434_is_wknd', '\u0412\u044b\u0435\u0437\u0434_season',\n",
              "       '\u0417\u0430\u0435\u0437\u0434_\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f_diff_in_days',\n",
              "       '\u0417\u0430\u0435\u0437\u0434_\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f_diff_in_weeks',\n",
              "       '\u0417\u0430\u0435\u0437\u0434_\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f_diff_in_hours', '\u0412\u044b\u0435\u0437\u0434_\u0417\u0430\u0435\u0437\u0434_diff_in_days',\n",
              "       '\u0412\u044b\u0435\u0437\u0434_\u0417\u0430\u0435\u0437\u0434_diff_in_weeks', '\u0412\u044b\u0435\u0437\u0434_\u0417\u0430\u0435\u0437\u0434_diff_in_hours', '\u041c\u0418\u0420',\n",
              "       'ComfortBooking', 'TravelLine Pro', '\u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f', '\u0411\u0430\u043d\u043a\u043e\u0432\u0441\u043a\u0430\u044f \u043a\u0430\u0440\u0442\u0430',\n",
              "       '\u041e\u043f\u043b\u0430\u0442\u0430 \u043d\u0430\u043b\u0438\u0447\u043d\u044b\u043c\u0438', '\u0421 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u043e\u0439', '\u0421\u0411\u041f',\n",
              "       '\u041e\u0442\u043b\u043e\u0436\u0435\u043d\u043d\u0430\u044f \u044d\u043b\u0435\u043a\u0442\u0440\u043e\u043d\u043d\u0430\u044f \u043e\u043f\u043b\u0430\u0442\u0430', '\u0413\u0430\u0440\u0430\u043d\u0442\u0438\u044f \u0431\u0430\u043d\u043a\u043e\u0432\u0441\u043a\u043e\u0439 \u043a\u0430\u0440\u0442\u043e\u0439',\n",
              "       '\u041f\u0440\u0438 \u0437\u0430\u0441\u0435\u043b\u0435\u043d\u0438\u0438', '\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f multiple selection', '\u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u0437\u0430 \u043d\u043e\u0447\u044c',\n",
              "       '\u0412\u043d\u0435\u0441\u0435\u043d\u0430 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u0430 binary',\n",
              "       '\u041f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u0430 \u0443\u043c\u043d\u043e\u0436\u0435\u043d\u043d\u0430\u044f \u043d\u0430 \u0432\u0440\u0435\u043c\u044f \u0434\u043e \u043f\u0440\u0438\u0431\u044b\u0442\u0438\u044f',\n",
              "       '\u041f\u0440\u043e\u0446\u0435\u043d\u0442 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u0430 \u043e\u0442 \u0441\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u0438', '\u0413\u043e\u0441\u0442\u0435\u0439 \u043d\u0430 \u043d\u043e\u043c\u0435\u0440',\n",
              "       '\u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u043d\u0430 \u0433\u043e\u0441\u0442\u044f', '\u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u0437\u0430 \u043d\u043e\u043c\u0435\u0440', '\u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u0437\u0430 \u043d\u043e\u0447\u044c 1 \u043d\u043e\u043c\u0435\u0440',\n",
              "       '\u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c \u0437\u0430 \u043d\u043e\u0447\u044c 1 \u0433\u043e\u0441\u0442\u044f', '\u0411\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0443\u0442\u0440\u043e\u043c',\n",
              "       '\u0411\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0432\u0435\u0447\u0435\u0440\u043e\u043c', '\u0411\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u043d\u043e\u0447\u044c\u044e',\n",
              "       '\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b_\u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430 [\u041a\u0435\u0448\u0431\u044d\u043a. \u041c\u0418\u0420]: \u042d\u043a\u0432\u0430\u0439\u0440\u0438\u043d\u0433 ComfortBooking (\u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)',\n",
              "       '\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b_\u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430 [\u041a\u0435\u0448\u0431\u044d\u043a. \u041c\u0418\u0420]: \u042d\u043a\u0432\u0430\u0439\u0440\u0438\u043d\u0433 TravelLine Pro (\u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)',\n",
              "       '\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b_\u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)',\n",
              "       '\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b_\u0412\u043d\u0435\u0448\u043d\u044f\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u043e\u043f\u043b\u0430\u0442\u044b',\n",
              "       '\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b_\u0412\u043d\u0435\u0448\u043d\u044f\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u043e\u043f\u043b\u0430\u0442\u044b (\u0411\u0430\u043d\u043a\u043e\u0432\u0441\u043a\u0430\u044f \u043a\u0430\u0440\u0442\u0430)',\n",
              "       '\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b_\u0412\u043d\u0435\u0448\u043d\u044f\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u043e\u043f\u043b\u0430\u0442\u044b (\u041e\u043f\u043b\u0430\u0442\u0430 \u043d\u0430\u043b\u0438\u0447\u043d\u044b\u043c\u0438)',\n",
              "       '\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b_\u0412\u043d\u0435\u0448\u043d\u044f\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u043e\u043f\u043b\u0430\u0442\u044b (\u0421 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u043e\u0439)',\n",
              "       '\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b_\u0413\u0430\u0440\u0430\u043d\u0442\u0438\u044f \u0431\u0430\u043d\u043a\u043e\u0432\u0441\u043a\u043e\u0439 \u043a\u0430\u0440\u0442\u043e\u0439',\n",
              "       '\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b_\u041e\u0442\u043b\u043e\u0436\u0435\u043d\u043d\u0430\u044f \u044d\u043b\u0435\u043a\u0442\u0440\u043e\u043d\u043d\u0430\u044f \u043e\u043f\u043b\u0430\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)',\n",
              "       '\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b_\u041f\u0440\u0438 \u0437\u0430\u0441\u0435\u043b\u0435\u043d\u0438\u0438', '\u0418\u0441\u0442\u043e\u0447\u043d\u0438\u043a_OneTwoTrip',\n",
              "       '\u0418\u0441\u0442\u043e\u0447\u043d\u0438\u043a_booking', '\u0418\u0441\u0442\u043e\u0447\u043d\u0438\u043a_ostrovok', '\u0418\u0441\u0442\u043e\u0447\u043d\u0438\u043a_other',\n",
              "       '\u0418\u0441\u0442\u043e\u0447\u043d\u0438\u043a_\u0411\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u0438\u0437 \u044d\u043a\u0441\u0442\u0440\u0430\u043d\u0435\u0442\u0430', '\u0418\u0441\u0442\u043e\u0447\u043d\u0438\u043a_\u041f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0430 \u043b\u043e\u044f\u043b\u044c\u043d\u043e\u0441\u0442\u0438',\n",
              "       '\u0418\u0441\u0442\u043e\u0447\u043d\u0438\u043a_\u042f\u043d\u0434\u0435\u043a\u0441.\u041f\u0443\u0442\u0435\u0448\u0435\u0441\u0442\u0432\u0438\u044f', '\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f \u043d\u043e\u043c\u0435\u0440\u0430_\u041a\u043e\u0442\u0442\u0435\u0434\u0436 \u0441 3 \u0441\u043f\u0430\u043b\u044c\u043d\u044f\u043c\u0438',\n",
              "       '\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f \u043d\u043e\u043c\u0435\u0440\u0430_\u041d\u043e\u043c\u0435\u0440 \u00ab\u041b\u044e\u043a\u0441\u00bb', '\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f \u043d\u043e\u043c\u0435\u0440\u0430_\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb',\n",
              "       '\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f \u043d\u043e\u043c\u0435\u0440\u0430_\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0443\u0434\u0438\u044f\u00bb'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "selector.support_"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True, False, False,  True,  True,  True,  True,\n",
              "       False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True, False,  True,  True,  True, False,  True,\n",
              "        True,  True,  True,  True,  True,  True, False,  True,  True,\n",
              "        True,  True,  True, False,  True,  True, False,  True,  True,\n",
              "        True, False,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# catboost is good on defaults\n",
        "models_list = []\n",
        "scores_list = []\n",
        "y_pred = np.zeros(df_test.shape[0])\n",
        "splitter = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
        "for i, (train_index, test_index) in enumerate(splitter.split(X_train, y_train)):\n",
        "    X_fold_train, y_fold_train = X_train.iloc[train_index], y_train.iloc[train_index]\n",
        "    X_fold_test, y_fold_test = X_train.iloc[test_index], y_train.iloc[test_index]\n",
        "\n",
        "    model = CatBoostClassifier(\n",
        "        cat_features=CAT_FEATURES,\n",
        "        verbose=0,\n",
        "        eval_metric=EVAL_METRIC,\n",
        "        early_stopping_rounds=EARLY_STOPPING,\n",
        "    )\n",
        "\n",
        "    model.fit(X_fold_train, y_fold_train, eval_set=(X_fold_test, y_fold_test))\n",
        "\n",
        "    preds = model.predict_proba(X_fold_test)[:, 1]\n",
        "    score = roc_auc_score(y_fold_test, preds)\n",
        "\n",
        "    models_list.append(model)\n",
        "    scores_list.append(score)\n",
        "\n",
        "np.mean(scores_list), np.std(scores_list)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8604038938620333, 0.006062816823753102)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "if SEARCH_BEST_PARAMS:\n",
        "    study = optuna.create_study(\n",
        "        direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
        "    )\n",
        "    study.optimize(\n",
        "        lambda trial: objective(trial, X_train_lgbm, y_train, \"LightGBM\"),\n",
        "        n_trials=N_TRIALS - 15,\n",
        "        show_progress_bar=True,\n",
        "    )"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-21 21:56:14,953] A new study created in memory with name: no-name-0b654a55-3330-455c-949a-2538d7371036\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a43a822952e431d93bad4f0b30e2132",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2024-09-21 21:58:19,366] Trial 0 finished with value: 0.8583994683558867 and parameters: {'boosting_type': 'dart', 'num_leaves': 64, 'max_depth': 4, 'learning_rate': 0.055238410897498764, 'feature_fraction': 0.4348501673009197, 'lambda_l1': 8.661895281603577, 'lambda_l2': 6.011549002420345, 'min_child_samples': 72, 'bagging_fraction': 0.41235069657748147, 'bagging_freq': 7}. Best is trial 0 with value: 0.8583994683558867.\n",
            "[I 2024-09-21 21:58:25,624] Trial 1 finished with value: 0.8600574020899071 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 26, 'max_depth': 5, 'learning_rate': 0.16217936517334897, 'feature_fraction': 0.6591670111852694, 'lambda_l1': 2.913000172840221, 'lambda_l2': 6.118917094329073, 'min_child_samples': 18, 'bagging_fraction': 0.5752867891211308, 'bagging_freq': 3}. Best is trial 1 with value: 0.8600574020899071.\n",
            "[I 2024-09-21 21:59:55,914] Trial 2 finished with value: 0.8602790611151823 and parameters: {'boosting_type': 'dart', 'num_leaves': 56, 'max_depth': 7, 'learning_rate': 0.02347061968879934, 'feature_fraction': 0.764526911140863, 'lambda_l1': 1.706070712749228, 'lambda_l2': 0.65145087825981, 'min_child_samples': 96, 'bagging_fraction': 0.9793792198447356, 'bagging_freq': 6}. Best is trial 2 with value: 0.8602790611151823.\n",
            "[I 2024-09-21 21:59:59,857] Trial 3 finished with value: 0.8594360254624146 and parameters: {'boosting_type': 'goss', 'num_leaves': 50, 'max_depth': 3, 'learning_rate': 0.15360130393226834, 'feature_fraction': 0.42063311266913106, 'lambda_l1': 9.093294700385743, 'lambda_l2': 2.588541036018569, 'min_child_samples': 68}. Best is trial 2 with value: 0.8602790611151823.\n",
            "[I 2024-09-21 22:00:04,014] Trial 4 finished with value: 0.8581869988965772 and parameters: {'boosting_type': 'goss', 'num_leaves': 26, 'max_depth': 10, 'learning_rate': 0.2347885187747232, 'feature_fraction': 0.9636993649385135, 'lambda_l1': 8.94837867692606, 'lambda_l2': 5.979401888132041, 'min_child_samples': 93}. Best is trial 2 with value: 0.8602790611151823.\n",
            "[I 2024-09-21 22:01:33,091] Trial 5 finished with value: 0.8538169726865881 and parameters: {'boosting_type': 'dart', 'num_leaves': 39, 'max_depth': 6, 'learning_rate': 0.08869121921442981, 'feature_fraction': 0.8972425054911576, 'lambda_l1': 3.5681765136091994, 'lambda_l2': 2.8100641623641205, 'min_child_samples': 57, 'bagging_fraction': 0.4845545349848576, 'bagging_freq': 6}. Best is trial 2 with value: 0.8602790611151823.\n",
            "[I 2024-09-21 22:02:19,464] Trial 6 finished with value: 0.8562996773763316 and parameters: {'boosting_type': 'dart', 'num_leaves': 28, 'max_depth': 3, 'learning_rate': 0.2464838142519019, 'feature_fraction': 0.8241144063085704, 'lambda_l1': 7.290342673241833, 'lambda_l2': 7.712932196512773, 'min_child_samples': 12, 'bagging_fraction': 0.6150794371265635, 'bagging_freq': 1}. Best is trial 2 with value: 0.8602790611151823.\n",
            "[I 2024-09-21 22:02:22,471] Trial 7 finished with value: 0.858397058069019 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 15, 'max_depth': 5, 'learning_rate': 0.10430316338775664, 'feature_fraction': 0.8377637070028385, 'lambda_l1': 6.375937156080776, 'lambda_l2': 8.872240213020689, 'min_child_samples': 50, 'bagging_fraction': 0.471756547562981, 'bagging_freq': 5}. Best is trial 2 with value: 0.8602790611151823.\n",
            "[I 2024-09-21 22:02:25,386] Trial 8 finished with value: 0.8594464355057202 and parameters: {'boosting_type': 'goss', 'num_leaves': 54, 'max_depth': 7, 'learning_rate': 0.1339868953239794, 'feature_fraction': 0.4152514760464571, 'lambda_l1': 1.0798063785060512, 'lambda_l2': 0.3152604276816558, 'min_child_samples': 66}. Best is trial 2 with value: 0.8602790611151823.\n",
            "[I 2024-09-21 22:02:27,962] Trial 9 finished with value: 0.8575598231428824 and parameters: {'boosting_type': 'goss', 'num_leaves': 32, 'max_depth': 6, 'learning_rate': 0.2291098301774841, 'feature_fraction': 0.5372788992949735, 'lambda_l1': 0.7707221183781011, 'lambda_l2': 2.8982247776847667, 'min_child_samples': 20}. Best is trial 2 with value: 0.8602790611151823.\n",
            "[I 2024-09-21 22:03:44,053] Trial 10 finished with value: 0.8605477509234868 and parameters: {'boosting_type': 'dart', 'num_leaves': 85, 'max_depth': 9, 'learning_rate': 0.015208943928297636, 'feature_fraction': 0.7015187306048778, 'lambda_l1': 3.9790804967476054, 'lambda_l2': 0.15256787628653778, 'min_child_samples': 98, 'bagging_fraction': 0.9821328682808784, 'bagging_freq': 4}. Best is trial 10 with value: 0.8605477509234868.\n",
            "[I 2024-09-21 22:05:04,391] Trial 11 finished with value: 0.8604799482261521 and parameters: {'boosting_type': 'dart', 'num_leaves': 93, 'max_depth': 9, 'learning_rate': 0.01835519874941342, 'feature_fraction': 0.6999731382848587, 'lambda_l1': 4.326099430193638, 'lambda_l2': 0.10934759077830591, 'min_child_samples': 100, 'bagging_fraction': 0.978623168800851, 'bagging_freq': 4}. Best is trial 10 with value: 0.8605477509234868.\n",
            "[I 2024-09-21 22:06:03,775] Trial 12 finished with value: 0.8599287151468286 and parameters: {'boosting_type': 'dart', 'num_leaves': 97, 'max_depth': 9, 'learning_rate': 0.017318055252790773, 'feature_fraction': 0.6446713618171314, 'lambda_l1': 4.88883946795536, 'lambda_l2': 1.4990721854763356, 'min_child_samples': 100, 'bagging_fraction': 0.9897600790985702, 'bagging_freq': 3}. Best is trial 10 with value: 0.8605477509234868.\n",
            "[I 2024-09-21 22:07:43,277] Trial 13 finished with value: 0.8561827462515431 and parameters: {'boosting_type': 'dart', 'num_leaves': 95, 'max_depth': 9, 'learning_rate': 0.06567448992833927, 'feature_fraction': 0.5850453461001829, 'lambda_l1': 4.847390921526337, 'lambda_l2': 0.13239001686236396, 'min_child_samples': 78, 'bagging_fraction': 0.83081875877721, 'bagging_freq': 4}. Best is trial 10 with value: 0.8605477509234868.\n",
            "[I 2024-09-21 22:09:28,377] Trial 14 finished with value: 0.8611098264769588 and parameters: {'boosting_type': 'dart', 'num_leaves': 80, 'max_depth': 8, 'learning_rate': 0.02353980066877352, 'feature_fraction': 0.7146404372369975, 'lambda_l1': 2.9294801014827625, 'lambda_l2': 4.301118582479693, 'min_child_samples': 85, 'bagging_fraction': 0.8207939948373919, 'bagging_freq': 3}. Best is trial 14 with value: 0.8611098264769588.\n",
            "[I 2024-09-21 22:12:00,761] Trial 15 finished with value: 0.8392997788589371 and parameters: {'boosting_type': 'dart', 'num_leaves': 78, 'max_depth': 8, 'learning_rate': 0.2934072750225726, 'feature_fraction': 0.7626791568432525, 'lambda_l1': 2.5725681807901704, 'lambda_l2': 4.59725314615027, 'min_child_samples': 84, 'bagging_fraction': 0.796359547497075, 'bagging_freq': 2}. Best is trial 14 with value: 0.8611098264769588.\n",
            "[I 2024-09-21 22:12:12,144] Trial 16 finished with value: 0.8603689116058026 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 78, 'max_depth': 10, 'learning_rate': 0.05591835971230835, 'feature_fraction': 0.5597734008162901, 'lambda_l1': 6.25382769995306, 'lambda_l2': 4.156391424987822, 'min_child_samples': 40, 'bagging_fraction': 0.8409778830855048, 'bagging_freq': 3}. Best is trial 14 with value: 0.8611098264769588.\n",
            "[I 2024-09-21 22:14:15,511] Trial 17 finished with value: 0.846107345777145 and parameters: {'boosting_type': 'dart', 'num_leaves': 81, 'max_depth': 8, 'learning_rate': 0.11459696713161138, 'feature_fraction': 0.7457222283591181, 'lambda_l1': 0.014539524404754367, 'lambda_l2': 1.8137262231653253, 'min_child_samples': 86, 'bagging_fraction': 0.7366888821986693, 'bagging_freq': 1}. Best is trial 14 with value: 0.8611098264769588.\n",
            "[I 2024-09-21 22:16:23,545] Trial 18 finished with value: 0.8583889960715435 and parameters: {'boosting_type': 'dart', 'num_leaves': 68, 'max_depth': 8, 'learning_rate': 0.04549022989003261, 'feature_fraction': 0.6276835368761836, 'lambda_l1': 2.422914384286307, 'lambda_l2': 9.751457281064663, 'min_child_samples': 39, 'bagging_fraction': 0.885859368874199, 'bagging_freq': 5}. Best is trial 14 with value: 0.8611098264769588.\n",
            "[I 2024-09-21 22:16:28,661] Trial 19 finished with value: 0.8598606487078457 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 86, 'max_depth': 10, 'learning_rate': 0.1857065514815792, 'feature_fraction': 0.5187167083556798, 'lambda_l1': 3.9771086646740557, 'lambda_l2': 3.9564006318932816, 'min_child_samples': 84, 'bagging_fraction': 0.9147570034736743, 'bagging_freq': 2}. Best is trial 14 with value: 0.8611098264769588.\n",
            "[I 2024-09-21 22:17:58,729] Trial 20 finished with value: 0.8568295205835834 and parameters: {'boosting_type': 'dart', 'num_leaves': 68, 'max_depth': 8, 'learning_rate': 0.08212319869612082, 'feature_fraction': 0.8312437199753491, 'lambda_l1': 5.575954218692617, 'lambda_l2': 7.103425450083497, 'min_child_samples': 59, 'bagging_fraction': 0.6810225789156616, 'bagging_freq': 5}. Best is trial 14 with value: 0.8611098264769588.\n",
            "[I 2024-09-21 22:19:09,002] Trial 21 finished with value: 0.8607329760142297 and parameters: {'boosting_type': 'dart', 'num_leaves': 88, 'max_depth': 9, 'learning_rate': 0.015306699513039401, 'feature_fraction': 0.7055455506771616, 'lambda_l1': 3.4667798146950264, 'lambda_l2': 1.3225506032930974, 'min_child_samples': 100, 'bagging_fraction': 0.9337338516796632, 'bagging_freq': 4}. Best is trial 14 with value: 0.8611098264769588.\n",
            "[I 2024-09-21 22:20:19,059] Trial 22 finished with value: 0.8590356790958531 and parameters: {'boosting_type': 'dart', 'num_leaves': 87, 'max_depth': 9, 'learning_rate': 0.010555186052950067, 'feature_fraction': 0.709620671906576, 'lambda_l1': 3.3187817333903604, 'lambda_l2': 1.5786083017266619, 'min_child_samples': 89, 'bagging_fraction': 0.9098586758773998, 'bagging_freq': 4}. Best is trial 14 with value: 0.8611098264769588.\n",
            "[I 2024-09-21 22:23:06,123] Trial 23 finished with value: 0.8589940495707855 and parameters: {'boosting_type': 'dart', 'num_leaves': 72, 'max_depth': 7, 'learning_rate': 0.038047890619505226, 'feature_fraction': 0.7162298179199247, 'lambda_l1': 1.9488599372538746, 'lambda_l2': 1.1406356013857484, 'min_child_samples': 77, 'bagging_fraction': 0.76064836769509, 'bagging_freq': 4}. Best is trial 14 with value: 0.8611098264769588.\n",
            "[I 2024-09-21 22:25:55,086] Trial 24 finished with value: 0.8541357752246934 and parameters: {'boosting_type': 'dart', 'num_leaves': 89, 'max_depth': 9, 'learning_rate': 0.08490995469636389, 'feature_fraction': 0.7945462032341207, 'lambda_l1': 3.957293062523805, 'lambda_l2': 3.1875563971224787, 'min_child_samples': 92, 'bagging_fraction': 0.9255573053677162, 'bagging_freq': 3}. Best is trial 14 with value: 0.8611098264769588.\n",
            "[W 2024-09-21 22:27:53,638] Trial 25 failed with parameters: {'boosting_type': 'dart', 'num_leaves': 98, 'max_depth': 8, 'learning_rate': 0.03752173169812073, 'feature_fraction': 0.6100951606786418, 'lambda_l1': 5.773976183790456, 'lambda_l2': 5.056254561425493, 'min_child_samples': 81, 'bagging_fraction': 0.8650872197386723, 'bagging_freq': 2} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/seara/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"/tmp/ipykernel_1223169/2989494471.py\", line 6, in <lambda>\n",
            "    lambda trial: objective(trial, X_train_lgbm, y_train, \"LightGBM\"),\n",
            "  File \"/home/seara/Desktop/Github/HSE_hack/fisting.py\", line 185, in objective\n",
            "    model, y_pred = model_types_dict[model_type](trial, train, val, **kwargs)\n",
            "  File \"/home/seara/Desktop/Github/HSE_hack/fisting.py\", line 97, in fit_lgbm\n",
            "    model.fit(\n",
            "  File \"/home/seara/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1284, in fit\n",
            "    super().fit(\n",
            "  File \"/home/seara/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 955, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/home/seara/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/lightgbm/engine.py\", line 307, in train\n",
            "    booster.update(fobj=fobj)\n",
            "  File \"/home/seara/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/lightgbm/basic.py\", line 4136, in update\n",
            "    _LIB.LGBM_BoosterUpdateOneIter(\n",
            "KeyboardInterrupt\n",
            "[W 2024-09-21 22:27:53,640] Trial 25 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m SEARCH_BEST_PARAMS:\n\u001b[1;32m      2\u001b[0m     study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m      3\u001b[0m         direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m, sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39mRANDOM_SEED)\n\u001b[1;32m      4\u001b[0m     )\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_lgbm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLightGBM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_TRIALS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
            "Cell \u001b[0;32mIn[13], line 6\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m SEARCH_BEST_PARAMS:\n\u001b[1;32m      2\u001b[0m     study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m      3\u001b[0m         direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m, sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39mRANDOM_SEED)\n\u001b[1;32m      4\u001b[0m     )\n\u001b[1;32m      5\u001b[0m     study\u001b[38;5;241m.\u001b[39moptimize(\n\u001b[0;32m----> 6\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_lgbm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLightGBM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      7\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mN_TRIALS,\n\u001b[1;32m      8\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m     )\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/fisting.py:185\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial, X_train, y_train, model_type, return_models, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m train \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39miloc[train_index], y_train\u001b[38;5;241m.\u001b[39miloc[train_index]\n\u001b[1;32m    183\u001b[0m val \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39miloc[val_index], y_train\u001b[38;5;241m.\u001b[39miloc[val_index]\n\u001b[0;32m--> 185\u001b[0m model, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_types_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m scores\u001b[38;5;241m.\u001b[39mappend(roc_auc_score(val[\u001b[38;5;241m1\u001b[39m], y_pred[:, \u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    187\u001b[0m models\u001b[38;5;241m.\u001b[39mappend(model)\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/fisting.py:97\u001b[0m, in \u001b[0;36mfit_lgbm\u001b[0;34m(trial, train, val)\u001b[0m\n\u001b[1;32m     87\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mearly_stopping_round\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[1;32m     89\u001b[0m model \u001b[38;5;241m=\u001b[39m LGBMClassifier(\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m     91\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m     random_state\u001b[38;5;241m=\u001b[39mRANDOM_SEED,\n\u001b[1;32m     95\u001b[0m )\n\u001b[0;32m---> 97\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEVAL_METRIC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCAT_FEATURES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_val)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, preds\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/lightgbm/sklearn.py:1284\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1281\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1282\u001b[0m             valid_sets\u001b[38;5;241m.\u001b[39mappend((valid_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform(valid_y)))\n\u001b[0;32m-> 1284\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_class_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_class_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/lightgbm/sklearn.py:955\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    952\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    953\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mbest_iteration\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/lightgbm/engine.py:307\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    296\u001b[0m     cb(\n\u001b[1;32m    297\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[1;32m    298\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m         )\n\u001b[1;32m    305\u001b[0m     )\n\u001b[0;32m--> 307\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/lightgbm/basic.py:4136\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   4133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   4134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4135\u001b[0m _safe_call(\n\u001b[0;32m-> 4136\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4137\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4139\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4140\u001b[0m )\n\u001b[1;32m   4141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   4142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "if SEARCH_BEST_PARAMS:\n",
        "    lgbm_best_params = study.best_params\n",
        "else:\n",
        "    lgbm_best_params = {\n",
        "        \"boosting_type\": \"dart\",\n",
        "        \"num_leaves\": 80,\n",
        "        \"max_depth\": 8,\n",
        "        \"learning_rate\": 0.02353980066877352,\n",
        "        \"feature_fraction\": 0.7146404372369975,\n",
        "        \"lambda_l1\": 2.9294801014827625,\n",
        "        \"lambda_l2\": 4.301118582479693,\n",
        "        \"min_child_samples\": 85,\n",
        "        \"bagging_fraction\": 0.8207939948373919,\n",
        "        \"bagging_freq\": 3,\n",
        "    }\n",
        "\n",
        "lgbm_best_value, lgbm_best_models = objective(\n",
        "    optuna.trial.FixedTrial(lgbm_best_params),\n",
        "    X_train_lgbm,\n",
        "    y_train,\n",
        "    \"LightGBM\",\n",
        "    return_models=True,\n",
        ")\n",
        "\n",
        "print(f\"Best LightGBM RMSE: {lgbm_best_value}\\n\\n\")\n",
        "print(\"Best LightGBM params:\")\n",
        "print(*[f\"'{key}': {value},\" for key, value in lgbm_best_params.items()], sep=\"\\n\")"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best LightGBM RMSE: 0.8611098264769588\n",
            "\n",
            "\n",
            "Best LightGBM params:\n",
            "'boosting_type': dart,\n",
            "'num_leaves': 80,\n",
            "'max_depth': 8,\n",
            "'learning_rate': 0.02353980066877352,\n",
            "'feature_fraction': 0.7146404372369975,\n",
            "'lambda_l1': 2.9294801014827625,\n",
            "'lambda_l2': 4.301118582479693,\n",
            "'min_child_samples': 85,\n",
            "'bagging_fraction': 0.8207939948373919,\n",
            "'bagging_freq': 3,\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "if SEARCH_BEST_PARAMS:\n",
        "    study = optuna.create_study(\n",
        "        direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
        "    )\n",
        "    study.optimize(\n",
        "        lambda trial: objective(trial, X_train_forest, y_train, \"RandomForest\"),\n",
        "        n_trials=N_TRIALS,\n",
        "        n_jobs=-1,\n",
        "        show_progress_bar=True,\n",
        "    )"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-21 22:34:28,072] A new study created in memory with name: no-name-b3153734-6743-45ee-b44b-751212972ae8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37c7b806df5244c38ff12a0b09df2602",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2024-09-21 22:36:22,785] Trial 8 finished with value: 0.8543033831840481 and parameters: {'n_estimators': 94, 'max_depth': 15, 'min_samples_split': 48, 'min_samples_leaf': 45, 'max_features': 0.08342036906580597}. Best is trial 8 with value: 0.8543033831840481.\n",
            "[I 2024-09-21 22:36:24,813] Trial 9 finished with value: 0.8594489110962236 and parameters: {'n_estimators': 86, 'max_depth': 8, 'min_samples_split': 42, 'min_samples_leaf': 36, 'max_features': 0.5906680603149131}. Best is trial 9 with value: 0.8594489110962236.\n",
            "[I 2024-09-21 22:36:59,678] Trial 3 finished with value: 0.856373796720647 and parameters: {'n_estimators': 160, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 35, 'max_features': 0.23902912385045083}. Best is trial 9 with value: 0.8594489110962236.\n",
            "[I 2024-09-21 22:37:34,469] Trial 7 finished with value: 0.8604503664788649 and parameters: {'n_estimators': 185, 'max_depth': 17, 'min_samples_split': 11, 'min_samples_leaf': 44, 'max_features': 0.16164208210938702}. Best is trial 7 with value: 0.8604503664788649.\n",
            "[I 2024-09-21 22:37:51,413] Trial 11 finished with value: 0.8586287551976721 and parameters: {'n_estimators': 177, 'max_depth': 16, 'min_samples_split': 13, 'min_samples_leaf': 12, 'max_features': 0.7980998506289265}. Best is trial 7 with value: 0.8604503664788649.\n",
            "[I 2024-09-21 22:37:52,430] Trial 0 finished with value: 0.8601082458018323 and parameters: {'n_estimators': 186, 'max_depth': 20, 'min_samples_split': 23, 'min_samples_leaf': 28, 'max_features': 0.7931898703650739}. Best is trial 7 with value: 0.8604503664788649.\n",
            "[I 2024-09-21 22:37:52,672] Trial 14 finished with value: 0.8602468003777224 and parameters: {'n_estimators': 231, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 16, 'max_features': 0.17729699788985565}. Best is trial 7 with value: 0.8604503664788649.\n",
            "[I 2024-09-21 22:37:55,829] Trial 1 finished with value: 0.8593703733549314 and parameters: {'n_estimators': 200, 'max_depth': 24, 'min_samples_split': 16, 'min_samples_leaf': 15, 'max_features': 0.5883355923492397}. Best is trial 7 with value: 0.8604503664788649.\n",
            "[I 2024-09-21 22:38:47,555] Trial 12 finished with value: 0.861230938370886 and parameters: {'n_estimators': 262, 'max_depth': 27, 'min_samples_split': 9, 'min_samples_leaf': 46, 'max_features': 0.4701993228526824}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:38:49,753] Trial 10 finished with value: 0.847252044222094 and parameters: {'n_estimators': 286, 'max_depth': 24, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 0.032199963949571586}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:38:50,560] Trial 4 finished with value: 0.8553319364890475 and parameters: {'n_estimators': 298, 'max_depth': 17, 'min_samples_split': 17, 'min_samples_leaf': 50, 'max_features': 0.07902172075275438}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:39:26,351] Trial 15 finished with value: 0.8603897386239876 and parameters: {'n_estimators': 318, 'max_depth': 8, 'min_samples_split': 39, 'min_samples_leaf': 12, 'max_features': 0.5771937248905429}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:39:50,292] Trial 23 finished with value: 0.8585843671152105 and parameters: {'n_estimators': 68, 'max_depth': 6, 'min_samples_split': 21, 'min_samples_leaf': 34, 'max_features': 0.4507990331152737}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:40:40,389] Trial 5 finished with value: 0.8607029650326282 and parameters: {'n_estimators': 399, 'max_depth': 19, 'min_samples_split': 11, 'min_samples_leaf': 38, 'max_features': 0.5412171813597507}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:40:54,048] Trial 6 finished with value: 0.8600297040262592 and parameters: {'n_estimators': 407, 'max_depth': 21, 'min_samples_split': 24, 'min_samples_leaf': 24, 'max_features': 0.6024630349544571}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:41:13,275] Trial 13 finished with value: 0.8601367848909479 and parameters: {'n_estimators': 389, 'max_depth': 16, 'min_samples_split': 8, 'min_samples_leaf': 22, 'max_features': 0.7136503475024358}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:41:33,940] Trial 18 finished with value: 0.8603342757757293 and parameters: {'n_estimators': 265, 'max_depth': 31, 'min_samples_split': 43, 'min_samples_leaf': 17, 'max_features': 0.38373824552972335}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:41:36,173] Trial 16 finished with value: 0.8606726537260295 and parameters: {'n_estimators': 319, 'max_depth': 22, 'min_samples_split': 7, 'min_samples_leaf': 19, 'max_features': 0.37546003916153314}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:41:42,495] Trial 24 finished with value: 0.8604473626381715 and parameters: {'n_estimators': 134, 'max_depth': 26, 'min_samples_split': 11, 'min_samples_leaf': 35, 'max_features': 0.7375324402178405}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:41:54,373] Trial 2 finished with value: 0.8609428131699243 and parameters: {'n_estimators': 493, 'max_depth': 24, 'min_samples_split': 18, 'min_samples_leaf': 31, 'max_features': 0.39589977252183783}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:42:12,445] Trial 22 finished with value: 0.8607425587456474 and parameters: {'n_estimators': 320, 'max_depth': 16, 'min_samples_split': 39, 'min_samples_leaf': 37, 'max_features': 0.166793254654251}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:43:01,826] Trial 21 finished with value: 0.8598758432480311 and parameters: {'n_estimators': 356, 'max_depth': 8, 'min_samples_split': 22, 'min_samples_leaf': 30, 'max_features': 0.8709447426905312}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:43:11,677] Trial 17 finished with value: 0.8600665555027728 and parameters: {'n_estimators': 423, 'max_depth': 12, 'min_samples_split': 38, 'min_samples_leaf': 21, 'max_features': 0.9526751565217484}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:43:25,358] Trial 20 finished with value: 0.859516424338121 and parameters: {'n_estimators': 370, 'max_depth': 14, 'min_samples_split': 15, 'min_samples_leaf': 20, 'max_features': 0.8385059380369984}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:43:28,732] Trial 25 finished with value: 0.8609278971059056 and parameters: {'n_estimators': 411, 'max_depth': 32, 'min_samples_split': 28, 'min_samples_leaf': 41, 'max_features': 0.37093116266730775}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:43:39,825] Trial 26 finished with value: 0.8608891871460079 and parameters: {'n_estimators': 418, 'max_depth': 32, 'min_samples_split': 34, 'min_samples_leaf': 41, 'max_features': 0.3682455019915143}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:43:45,440] Trial 19 finished with value: 0.860968911509782 and parameters: {'n_estimators': 498, 'max_depth': 22, 'min_samples_split': 23, 'min_samples_leaf': 40, 'max_features': 0.7717168642954451}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:43:46,373] Trial 28 finished with value: 0.8611826291441685 and parameters: {'n_estimators': 427, 'max_depth': 32, 'min_samples_split': 30, 'min_samples_leaf': 42, 'max_features': 0.35835480822739235}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:43:46,419] Trial 27 finished with value: 0.8609077181494665 and parameters: {'n_estimators': 472, 'max_depth': 32, 'min_samples_split': 30, 'min_samples_leaf': 42, 'max_features': 0.37378794043395347}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:43:49,835] Trial 29 finished with value: 0.8612870466853071 and parameters: {'n_estimators': 425, 'max_depth': 31, 'min_samples_split': 33, 'min_samples_leaf': 44, 'max_features': 0.38331686104122775}. Best is trial 29 with value: 0.8612870466853071.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# \u0412\u044b\u0432\u043e\u0434 \u043b\u0443\u0447\u0448\u0438\u0445 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u0438 \u043c\u0435\u0442\u0440\u0438\u043a\n",
        "if SEARCH_BEST_PARAMS:\n",
        "    rf_best_params = study.best_params\n",
        "else:\n",
        "    rf_best_params = {\n",
        "        \"n_estimators\": 425,\n",
        "        \"max_depth\": 31,\n",
        "        \"min_samples_split\": 33,\n",
        "        \"min_samples_leaf\": 44,\n",
        "        \"max_features\": 0.38331686104122775,\n",
        "    }\n",
        "\n",
        "rf_best_value, rf_best_models = objective(\n",
        "    optuna.trial.FixedTrial(rf_best_params),\n",
        "    X_train_forest,\n",
        "    y_train,\n",
        "    \"RandomForest\",\n",
        "    return_models=True,\n",
        ")\n",
        "\n",
        "print(f\"Best Random Forest RMSE: {rf_best_value}\\n\\n\")\n",
        "print(\"Best Random Forest params:\")\n",
        "print(*[f\"'{key}': {value},\" for key, value in rf_best_params.items()], sep=\"\\n\")"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Random Forest RMSE: 0.8612870466853071\n",
            "\n",
            "\n",
            "Best Random Forest params:\n",
            "'n_estimators': 425,\n",
            "'max_depth': 31,\n",
            "'min_samples_split': 33,\n",
            "'min_samples_leaf': 44,\n",
            "'max_features': 0.38331686104122775,\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "if SEARCH_BEST_PARAMS:\n",
        "    study = optuna.create_study(\n",
        "        direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
        "    )\n",
        "    study.optimize(\n",
        "        lambda trial: objective(trial, X_train_forest, y_train, \"ExtraTrees\"),\n",
        "        n_trials=N_TRIALS - 15,\n",
        "        n_jobs=1,\n",
        "        show_progress_bar=True,\n",
        "    )"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-21 22:44:54,418] A new study created in memory with name: no-name-a75b9a82-c594-402a-a038-c6cc79c6c16f\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d699da6cb07e462eb4b2636fc03723b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/15 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2024-09-21 22:44:59,396] Trial 0 finished with value: 0.8551317486861899 and parameters: {'n_estimators': 218, 'max_depth': 31, 'min_samples_split': 37, 'min_samples_leaf': 30, 'max_features': 0.15601864044243652}. Best is trial 0 with value: 0.8551317486861899.\n",
            "[I 2024-09-21 22:45:01,395] Trial 1 finished with value: 0.846770334777635 and parameters: {'n_estimators': 120, 'max_depth': 3, 'min_samples_split': 44, 'min_samples_leaf': 31, 'max_features': 0.7080725777960455}. Best is trial 0 with value: 0.8551317486861899.\n",
            "[I 2024-09-21 22:45:03,062] Trial 2 finished with value: 0.8585579156835859 and parameters: {'n_estimators': 59, 'max_depth': 32, 'min_samples_split': 42, 'min_samples_leaf': 11, 'max_features': 0.18182496720710062}. Best is trial 2 with value: 0.8585579156835859.\n",
            "[I 2024-09-21 22:45:06,712] Trial 3 finished with value: 0.8599164836062212 and parameters: {'n_estimators': 132, 'max_depth': 11, 'min_samples_split': 27, 'min_samples_leaf': 22, 'max_features': 0.2912291401980419}. Best is trial 3 with value: 0.8599164836062212.\n",
            "[I 2024-09-21 22:45:13,100] Trial 4 finished with value: 0.8544093571137644 and parameters: {'n_estimators': 325, 'max_depth': 6, 'min_samples_split': 16, 'min_samples_leaf': 19, 'max_features': 0.45606998421703593}. Best is trial 3 with value: 0.8599164836062212.\n",
            "[I 2024-09-21 22:45:16,774] Trial 5 finished with value: 0.8247799970099619 and parameters: {'n_estimators': 404, 'max_depth': 8, 'min_samples_split': 27, 'min_samples_leaf': 30, 'max_features': 0.046450412719997725}. Best is trial 3 with value: 0.8599164836062212.\n",
            "[I 2024-09-21 22:45:29,996] Trial 6 finished with value: 0.8584741371013029 and parameters: {'n_estimators': 324, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 48, 'max_features': 0.9656320330745594}. Best is trial 3 with value: 0.8599164836062212.\n",
            "[I 2024-09-21 22:45:43,206] Trial 7 finished with value: 0.860252457598218 and parameters: {'n_estimators': 414, 'max_depth': 11, 'min_samples_split': 6, 'min_samples_leaf': 35, 'max_features': 0.4401524937396013}. Best is trial 7 with value: 0.860252457598218.\n",
            "[I 2024-09-21 22:45:46,100] Trial 8 finished with value: 0.857771358182689 and parameters: {'n_estimators': 105, 'max_depth': 17, 'min_samples_split': 3, 'min_samples_leaf': 46, 'max_features': 0.2587799816000169}. Best is trial 7 with value: 0.860252457598218.\n",
            "[I 2024-09-21 22:45:52,667] Trial 9 finished with value: 0.8563620205139746 and parameters: {'n_estimators': 348, 'max_depth': 11, 'min_samples_split': 27, 'min_samples_leaf': 28, 'max_features': 0.18485445552552704}. Best is trial 7 with value: 0.860252457598218.\n",
            "[I 2024-09-21 22:46:27,650] Trial 10 finished with value: 0.8551312305553204 and parameters: {'n_estimators': 490, 'max_depth': 23, 'min_samples_split': 14, 'min_samples_leaf': 1, 'max_features': 0.6400885024675562}. Best is trial 7 with value: 0.860252457598218.\n",
            "[I 2024-09-21 22:46:34,800] Trial 11 finished with value: 0.8597797719103643 and parameters: {'n_estimators': 205, 'max_depth': 15, 'min_samples_split': 17, 'min_samples_leaf': 40, 'max_features': 0.37960424342022336}. Best is trial 7 with value: 0.860252457598218.\n",
            "[I 2024-09-21 22:46:59,346] Trial 12 finished with value: 0.8608913874445427 and parameters: {'n_estimators': 497, 'max_depth': 13, 'min_samples_split': 33, 'min_samples_leaf': 17, 'max_features': 0.5950385565501397}. Best is trial 12 with value: 0.8608913874445427.\n",
            "[I 2024-09-21 22:47:28,767] Trial 13 finished with value: 0.8596898871702408 and parameters: {'n_estimators': 487, 'max_depth': 22, 'min_samples_split': 34, 'min_samples_leaf': 14, 'max_features': 0.6263510221562969}. Best is trial 12 with value: 0.8608913874445427.\n",
            "[I 2024-09-21 22:47:54,579] Trial 14 finished with value: 0.8598734229127756 and parameters: {'n_estimators': 422, 'max_depth': 13, 'min_samples_split': 50, 'min_samples_leaf': 38, 'max_features': 0.8052519186638233}. Best is trial 12 with value: 0.8608913874445427.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# \u0412\u044b\u0432\u043e\u0434 \u043b\u0443\u0447\u0448\u0438\u0445 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u0438 \u043c\u0435\u0442\u0440\u0438\u043a\n",
        "if SEARCH_BEST_PARAMS:\n",
        "    et_best_params = study.best_params\n",
        "else:\n",
        "    et_best_params = {\n",
        "        \"n_estimators\": 497,\n",
        "        \"max_depth\": 13,\n",
        "        \"min_samples_split\": 33,\n",
        "        \"min_samples_leaf\": 17,\n",
        "        \"max_features\": 0.5950385565501397,\n",
        "    }\n",
        "\n",
        "et_best_value, et_best_models = objective(\n",
        "    optuna.trial.FixedTrial(et_best_params),\n",
        "    X_train_forest,\n",
        "    y_train,\n",
        "    \"ExtraTrees\",\n",
        "    return_models=True,\n",
        ")\n",
        "\n",
        "print(f\"Best Extra Trees RMSE: {et_best_value}\\n\\n\")\n",
        "print(\"Best Extra Trees params:\")\n",
        "print(*[f\"'{key}': {value},\" for key, value in et_best_params.items()], sep=\"\\n\")"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Extra Trees RMSE: 0.8608913874445427\n",
            "\n",
            "\n",
            "Best Extra Trees params:\n",
            "'n_estimators': 497,\n",
            "'max_depth': 13,\n",
            "'min_samples_split': 33,\n",
            "'min_samples_leaf': 17,\n",
            "'max_features': 0.5950385565501397,\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "catboost_y_pred = np.zeros(df_test.shape[0])\n",
        "\n",
        "for model in models_list:\n",
        "    catboost_y_pred += model.predict_proba(df_test)[:, 1]\n",
        "catboost_y_pred = catboost_y_pred / len(models_list)\n",
        "\n",
        "lgbm_y_pred = np.zeros(df_test_lgbm.shape[0])\n",
        "\n",
        "for model in lgbm_best_models:\n",
        "    lgbm_y_pred += model.predict_proba(df_test_lgbm)[:, 1]\n",
        "lgbm_y_pred = lgbm_y_pred / len(models_list)\n",
        "\n",
        "\n",
        "rf_y_pred = np.zeros(df_test_forest.shape[0])\n",
        "\n",
        "for model in rf_best_models:\n",
        "    rf_y_pred += model.predict_proba(df_test_forest)[:, 1]\n",
        "rf_y_pred = rf_y_pred / len(models_list)\n",
        "\n",
        "\n",
        "et_y_pred = np.zeros(df_test_forest.shape[0])\n",
        "\n",
        "for model in et_best_models:\n",
        "    et_y_pred += model.predict_proba(df_test_forest)[:, 1]\n",
        "et_y_pred = et_y_pred / len(models_list)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "final = np.zeros(df_test.shape[0])\n",
        "\n",
        "final += catboost_y_pred + lgbm_y_pred + rf_y_pred + et_y_pred\n",
        "final = final / 4"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "submissiom = pd.DataFrame(final)\n",
        "submissiom.to_csv(\"4x_blending.csv\", index=False, header=False)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    }
  ]
}
