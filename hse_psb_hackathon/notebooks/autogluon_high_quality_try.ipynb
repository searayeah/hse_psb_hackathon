{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {},
  "cells": [
    {
      "metadata": {},
      "source": [
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import optuna\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from autogluon.tabular import TabularPredictor\n",
        "from catboost import CatBoostClassifier\n",
        "from fisting import fit_catboost, fit_et, fit_lgbm, fit_rf, objective\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "\n",
        "df_train = pd.read_excel(\"train.xlsx\")\n",
        "df_test = pd.read_excel(\"test.xlsx\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "df_train"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>\u2116 \u0431\u0440\u043e\u043d\u0438</th>\n",
              "      <th>\u041d\u043e\u043c\u0435\u0440\u043e\u0432</th>\n",
              "      <th>\u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c</th>\n",
              "      <th>\u0412\u043d\u0435\u0441\u0435\u043d\u0430 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u0430</th>\n",
              "      <th>\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b</th>\n",
              "      <th>\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f</th>\n",
              "      <th>\u0414\u0430\u0442\u0430 \u043e\u0442\u043c\u0435\u043d\u044b</th>\n",
              "      <th>\u0417\u0430\u0435\u0437\u0434</th>\n",
              "      <th>\u041d\u043e\u0447\u0435\u0439</th>\n",
              "      <th>\u0412\u044b\u0435\u0437\u0434</th>\n",
              "      <th>\u0418\u0441\u0442\u043e\u0447\u043d\u0438\u043a</th>\n",
              "      <th>\u0421\u0442\u0430\u0442\u0443\u0441 \u0431\u0440\u043e\u043d\u0438</th>\n",
              "      <th>\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f \u043d\u043e\u043c\u0435\u0440\u0430</th>\n",
              "      <th>\u0413\u043e\u0441\u0442\u0435\u0439</th>\n",
              "      <th>\u0413\u043e\u0441\u0442\u0438\u043d\u0438\u0446\u0430</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>20230428-6634-194809261</td>\n",
              "      <td>1</td>\n",
              "      <td>25700.0</td>\n",
              "      <td>0</td>\n",
              "      <td>\u0412\u043d\u0435\u0448\u043d\u044f\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u043e\u043f\u043b\u0430\u0442\u044b</td>\n",
              "      <td>2023-04-20 20:37:30</td>\n",
              "      <td>2023-04-20 20:39:15</td>\n",
              "      <td>2023-04-28 15:00:00</td>\n",
              "      <td>3</td>\n",
              "      <td>2023-05-01 12:00:00</td>\n",
              "      <td>\u042f\u043d\u0434\u0435\u043a\u0441.\u041f\u0443\u0442\u0435\u0448\u0435\u0441\u0442\u0432\u0438\u044f</td>\n",
              "      <td>\u041e\u0442\u043c\u0435\u043d\u0430</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>20220711-6634-144460018</td>\n",
              "      <td>1</td>\n",
              "      <td>24800.0</td>\n",
              "      <td>12400</td>\n",
              "      <td>\u041e\u0442\u043b\u043e\u0436\u0435\u043d\u043d\u0430\u044f \u044d\u043b\u0435\u043a\u0442\u0440\u043e\u043d\u043d\u0430\u044f \u043e\u043f\u043b\u0430\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430...</td>\n",
              "      <td>2022-06-18 14:17:02</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2022-07-11 15:00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>2022-07-13 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>20221204-16563-171020423</td>\n",
              "      <td>1</td>\n",
              "      <td>25800.0</td>\n",
              "      <td>12900</td>\n",
              "      <td>\u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)</td>\n",
              "      <td>2022-11-14 22:59:30</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2022-12-04 15:00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>2022-12-06 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0443\u0434\u0438\u044f\u00bb</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>20230918-7491-223512699</td>\n",
              "      <td>1</td>\n",
              "      <td>10500.0</td>\n",
              "      <td>0</td>\n",
              "      <td>\u0412\u043d\u0435\u0448\u043d\u044f\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u043e\u043f\u043b\u0430\u0442\u044b (\u0421 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u043e\u0439)</td>\n",
              "      <td>2023-09-08 15:55:53</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2023-09-18 15:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-09-19 12:00:00</td>\n",
              "      <td>Bronevik.com(new)</td>\n",
              "      <td>\u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>20230529-6634-200121971</td>\n",
              "      <td>1</td>\n",
              "      <td>28690.0</td>\n",
              "      <td>28690</td>\n",
              "      <td>\u0421\u0438\u0441\u0442\u0435\u043c\u0430 \u0431\u044b\u0441\u0442\u0440\u044b\u0445 \u043f\u043b\u0430\u0442\u0435\u0436\u0435\u0439: \u042d\u043a\u0432\u0430\u0439\u0440\u0438\u043d\u0433 ComfortBoo...</td>\n",
              "      <td>2023-05-20 19:54:13</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2023-05-29 15:00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>2023-05-31 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u041b\u044e\u043a\u0441\u00bb</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26169</th>\n",
              "      <td>26169</td>\n",
              "      <td>20230310-7492-177993190</td>\n",
              "      <td>1</td>\n",
              "      <td>18240.0</td>\n",
              "      <td>9120</td>\n",
              "      <td>\u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)</td>\n",
              "      <td>2023-01-07 17:45:18</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2023-03-10 15:00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>2023-03-12 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26170</th>\n",
              "      <td>26170</td>\n",
              "      <td>20230625-16563-206126520</td>\n",
              "      <td>1</td>\n",
              "      <td>69600.0</td>\n",
              "      <td>23200</td>\n",
              "      <td>\u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)</td>\n",
              "      <td>2023-06-20 17:54:17</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2023-06-25 15:00:00</td>\n",
              "      <td>3</td>\n",
              "      <td>2023-06-28 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0443\u0434\u0438\u044f\u00bb</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26171</th>\n",
              "      <td>26171</td>\n",
              "      <td>20220624-7492-137587082</td>\n",
              "      <td>1</td>\n",
              "      <td>55600.0</td>\n",
              "      <td>13900</td>\n",
              "      <td>\u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)</td>\n",
              "      <td>2022-05-08 19:24:05</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2022-06-24 15:00:00</td>\n",
              "      <td>4</td>\n",
              "      <td>2022-06-28 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26172</th>\n",
              "      <td>26172</td>\n",
              "      <td>20220427-7491-125459150</td>\n",
              "      <td>1</td>\n",
              "      <td>6300.0</td>\n",
              "      <td>0</td>\n",
              "      <td>\u0413\u0430\u0440\u0430\u043d\u0442\u0438\u044f \u0431\u0430\u043d\u043a\u043e\u0432\u0441\u043a\u043e\u0439 \u043a\u0430\u0440\u0442\u043e\u0439</td>\n",
              "      <td>2022-02-19 09:55:50</td>\n",
              "      <td>2022-04-16 23:14:35</td>\n",
              "      <td>2022-04-27 15:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>2022-04-28 12:00:00</td>\n",
              "      <td>booking.com</td>\n",
              "      <td>\u041e\u0442\u043c\u0435\u043d\u0430</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26173</th>\n",
              "      <td>26173</td>\n",
              "      <td>20220816-6634-155783156</td>\n",
              "      <td>1</td>\n",
              "      <td>24600.0</td>\n",
              "      <td>24600</td>\n",
              "      <td>\u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)</td>\n",
              "      <td>2022-08-13 22:35:43</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2022-08-16 15:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>2022-08-17 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439</td>\n",
              "      <td>\u0410\u043f\u0430\u0440\u0442\u0430\u043c\u0435\u043d\u0442\u044b \u0441 2 \u0441\u043f\u0430\u043b\u044c\u043d\u044f\u043c\u0438 \u0441 \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u044b\u043c \u0432\u0445\u043e\u0434\u043e\u043c</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26174 rows \u00d7 16 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0                   \u2116 \u0431\u0440\u043e\u043d\u0438  \u041d\u043e\u043c\u0435\u0440\u043e\u0432  \u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c  \\\n",
              "0               0   20230428-6634-194809261        1    25700.0   \n",
              "1               1   20220711-6634-144460018        1    24800.0   \n",
              "2               2  20221204-16563-171020423        1    25800.0   \n",
              "3               3   20230918-7491-223512699        1    10500.0   \n",
              "4               4   20230529-6634-200121971        1    28690.0   \n",
              "...           ...                       ...      ...        ...   \n",
              "26169       26169   20230310-7492-177993190        1    18240.0   \n",
              "26170       26170  20230625-16563-206126520        1    69600.0   \n",
              "26171       26171   20220624-7492-137587082        1    55600.0   \n",
              "26172       26172   20220427-7491-125459150        1     6300.0   \n",
              "26173       26173   20220816-6634-155783156        1    24600.0   \n",
              "\n",
              "       \u0412\u043d\u0435\u0441\u0435\u043d\u0430 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u0430                                      \u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b  \\\n",
              "0                       0                             \u0412\u043d\u0435\u0448\u043d\u044f\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u043e\u043f\u043b\u0430\u0442\u044b   \n",
              "1                   12400  \u041e\u0442\u043b\u043e\u0436\u0435\u043d\u043d\u0430\u044f \u044d\u043b\u0435\u043a\u0442\u0440\u043e\u043d\u043d\u0430\u044f \u043e\u043f\u043b\u0430\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430...   \n",
              "2                   12900             \u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)   \n",
              "3                       0             \u0412\u043d\u0435\u0448\u043d\u044f\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u043e\u043f\u043b\u0430\u0442\u044b (\u0421 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u043e\u0439)   \n",
              "4                   28690  \u0421\u0438\u0441\u0442\u0435\u043c\u0430 \u0431\u044b\u0441\u0442\u0440\u044b\u0445 \u043f\u043b\u0430\u0442\u0435\u0436\u0435\u0439: \u042d\u043a\u0432\u0430\u0439\u0440\u0438\u043d\u0433 ComfortBoo...   \n",
              "...                   ...                                                ...   \n",
              "26169                9120             \u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)   \n",
              "26170               23200             \u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)   \n",
              "26171               13900             \u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)   \n",
              "26172                   0                         \u0413\u0430\u0440\u0430\u043d\u0442\u0438\u044f \u0431\u0430\u043d\u043a\u043e\u0432\u0441\u043a\u043e\u0439 \u043a\u0430\u0440\u0442\u043e\u0439   \n",
              "26173               24600             \u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)   \n",
              "\n",
              "        \u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f         \u0414\u0430\u0442\u0430 \u043e\u0442\u043c\u0435\u043d\u044b               \u0417\u0430\u0435\u0437\u0434  \u041d\u043e\u0447\u0435\u0439  \\\n",
              "0     2023-04-20 20:37:30 2023-04-20 20:39:15 2023-04-28 15:00:00      3   \n",
              "1     2022-06-18 14:17:02                 NaT 2022-07-11 15:00:00      2   \n",
              "2     2022-11-14 22:59:30                 NaT 2022-12-04 15:00:00      2   \n",
              "3     2023-09-08 15:55:53                 NaT 2023-09-18 15:00:00      1   \n",
              "4     2023-05-20 19:54:13                 NaT 2023-05-29 15:00:00      2   \n",
              "...                   ...                 ...                 ...    ...   \n",
              "26169 2023-01-07 17:45:18                 NaT 2023-03-10 15:00:00      2   \n",
              "26170 2023-06-20 17:54:17                 NaT 2023-06-25 15:00:00      3   \n",
              "26171 2022-05-08 19:24:05                 NaT 2022-06-24 15:00:00      4   \n",
              "26172 2022-02-19 09:55:50 2022-04-16 23:14:35 2022-04-27 15:00:00      1   \n",
              "26173 2022-08-13 22:35:43                 NaT 2022-08-16 15:00:00      1   \n",
              "\n",
              "                    \u0412\u044b\u0435\u0437\u0434            \u0418\u0441\u0442\u043e\u0447\u043d\u0438\u043a \u0421\u0442\u0430\u0442\u0443\u0441 \u0431\u0440\u043e\u043d\u0438  \\\n",
              "0     2023-05-01 12:00:00  \u042f\u043d\u0434\u0435\u043a\u0441.\u041f\u0443\u0442\u0435\u0448\u0435\u0441\u0442\u0432\u0438\u044f       \u041e\u0442\u043c\u0435\u043d\u0430   \n",
              "1     2022-07-13 12:00:00    \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442     \u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439   \n",
              "2     2022-12-06 12:00:00    \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442     \u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439   \n",
              "3     2023-09-19 12:00:00   Bronevik.com(new)     \u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439   \n",
              "4     2023-05-31 12:00:00    \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442     \u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439   \n",
              "...                   ...                 ...          ...   \n",
              "26169 2023-03-12 12:00:00    \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442     \u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439   \n",
              "26170 2023-06-28 12:00:00    \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442     \u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439   \n",
              "26171 2022-06-28 12:00:00    \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442     \u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439   \n",
              "26172 2022-04-28 12:00:00         booking.com       \u041e\u0442\u043c\u0435\u043d\u0430   \n",
              "26173 2022-08-17 12:00:00    \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442     \u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439   \n",
              "\n",
              "                                   \u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f \u043d\u043e\u043c\u0435\u0440\u0430  \u0413\u043e\u0441\u0442\u0435\u0439  \u0413\u043e\u0441\u0442\u0438\u043d\u0438\u0446\u0430  \n",
              "0                                  \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb       2          1  \n",
              "1                                  \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb       2          1  \n",
              "2                                    \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0443\u0434\u0438\u044f\u00bb       2          4  \n",
              "3                                  \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb       1          3  \n",
              "4                                      \u041d\u043e\u043c\u0435\u0440 \u00ab\u041b\u044e\u043a\u0441\u00bb       4          1  \n",
              "...                                             ...     ...        ...  \n",
              "26169                              \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb       2          2  \n",
              "26170                                \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0443\u0434\u0438\u044f\u00bb       3          4  \n",
              "26171                              \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb       2          2  \n",
              "26172                              \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb       2          3  \n",
              "26173  \u0410\u043f\u0430\u0440\u0442\u0430\u043c\u0435\u043d\u0442\u044b \u0441 2 \u0441\u043f\u0430\u043b\u044c\u043d\u044f\u043c\u0438 \u0441 \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u044b\u043c \u0432\u0445\u043e\u0434\u043e\u043c       3          1  \n",
              "\n",
              "[26174 rows x 16 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "def prepare_df(df):\n",
        "    df = df.copy()\n",
        "    df = df.drop([\"Unnamed: 0\", \"\u2116 \u0431\u0440\u043e\u043d\u0438\"], axis=1)\n",
        "    df[\"\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f\"] = pd.to_datetime(df[\"\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f\"])\n",
        "    df[\"\u0417\u0430\u0435\u0437\u0434\"] = pd.to_datetime(df[\"\u0417\u0430\u0435\u0437\u0434\"])\n",
        "    df[\"\u0412\u044b\u0435\u0437\u0434\"] = pd.to_datetime(df[\"\u0412\u044b\u0435\u0437\u0434\"])\n",
        "    return df"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "def preprocess_df(df):\n",
        "    df = df.copy()\n",
        "    df = prepare_df(df)\n",
        "\n",
        "    return df"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "df_train = preprocess_df(df_train)\n",
        "df_test = preprocess_df(df_test)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "df_train"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>\u041d\u043e\u043c\u0435\u0440\u043e\u0432</th>\n",
              "      <th>\u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c</th>\n",
              "      <th>\u0412\u043d\u0435\u0441\u0435\u043d\u0430 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u0430</th>\n",
              "      <th>\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b</th>\n",
              "      <th>\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f</th>\n",
              "      <th>\u0414\u0430\u0442\u0430 \u043e\u0442\u043c\u0435\u043d\u044b</th>\n",
              "      <th>\u0417\u0430\u0435\u0437\u0434</th>\n",
              "      <th>\u041d\u043e\u0447\u0435\u0439</th>\n",
              "      <th>\u0412\u044b\u0435\u0437\u0434</th>\n",
              "      <th>\u0418\u0441\u0442\u043e\u0447\u043d\u0438\u043a</th>\n",
              "      <th>\u0421\u0442\u0430\u0442\u0443\u0441 \u0431\u0440\u043e\u043d\u0438</th>\n",
              "      <th>\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f \u043d\u043e\u043c\u0435\u0440\u0430</th>\n",
              "      <th>\u0413\u043e\u0441\u0442\u0435\u0439</th>\n",
              "      <th>\u0413\u043e\u0441\u0442\u0438\u043d\u0438\u0446\u0430</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>25700.0</td>\n",
              "      <td>0</td>\n",
              "      <td>\u0412\u043d\u0435\u0448\u043d\u044f\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u043e\u043f\u043b\u0430\u0442\u044b</td>\n",
              "      <td>2023-04-20 20:37:30</td>\n",
              "      <td>2023-04-20 20:39:15</td>\n",
              "      <td>2023-04-28 15:00:00</td>\n",
              "      <td>3</td>\n",
              "      <td>2023-05-01 12:00:00</td>\n",
              "      <td>\u042f\u043d\u0434\u0435\u043a\u0441.\u041f\u0443\u0442\u0435\u0448\u0435\u0441\u0442\u0432\u0438\u044f</td>\n",
              "      <td>\u041e\u0442\u043c\u0435\u043d\u0430</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>24800.0</td>\n",
              "      <td>12400</td>\n",
              "      <td>\u041e\u0442\u043b\u043e\u0436\u0435\u043d\u043d\u0430\u044f \u044d\u043b\u0435\u043a\u0442\u0440\u043e\u043d\u043d\u0430\u044f \u043e\u043f\u043b\u0430\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430...</td>\n",
              "      <td>2022-06-18 14:17:02</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2022-07-11 15:00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>2022-07-13 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>25800.0</td>\n",
              "      <td>12900</td>\n",
              "      <td>\u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)</td>\n",
              "      <td>2022-11-14 22:59:30</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2022-12-04 15:00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>2022-12-06 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0443\u0434\u0438\u044f\u00bb</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>10500.0</td>\n",
              "      <td>0</td>\n",
              "      <td>\u0412\u043d\u0435\u0448\u043d\u044f\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u043e\u043f\u043b\u0430\u0442\u044b (\u0421 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u043e\u0439)</td>\n",
              "      <td>2023-09-08 15:55:53</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2023-09-18 15:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-09-19 12:00:00</td>\n",
              "      <td>Bronevik.com(new)</td>\n",
              "      <td>\u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>28690.0</td>\n",
              "      <td>28690</td>\n",
              "      <td>\u0421\u0438\u0441\u0442\u0435\u043c\u0430 \u0431\u044b\u0441\u0442\u0440\u044b\u0445 \u043f\u043b\u0430\u0442\u0435\u0436\u0435\u0439: \u042d\u043a\u0432\u0430\u0439\u0440\u0438\u043d\u0433 ComfortBoo...</td>\n",
              "      <td>2023-05-20 19:54:13</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2023-05-29 15:00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>2023-05-31 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u041b\u044e\u043a\u0441\u00bb</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26169</th>\n",
              "      <td>1</td>\n",
              "      <td>18240.0</td>\n",
              "      <td>9120</td>\n",
              "      <td>\u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)</td>\n",
              "      <td>2023-01-07 17:45:18</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2023-03-10 15:00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>2023-03-12 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26170</th>\n",
              "      <td>1</td>\n",
              "      <td>69600.0</td>\n",
              "      <td>23200</td>\n",
              "      <td>\u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)</td>\n",
              "      <td>2023-06-20 17:54:17</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2023-06-25 15:00:00</td>\n",
              "      <td>3</td>\n",
              "      <td>2023-06-28 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0443\u0434\u0438\u044f\u00bb</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26171</th>\n",
              "      <td>1</td>\n",
              "      <td>55600.0</td>\n",
              "      <td>13900</td>\n",
              "      <td>\u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)</td>\n",
              "      <td>2022-05-08 19:24:05</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2022-06-24 15:00:00</td>\n",
              "      <td>4</td>\n",
              "      <td>2022-06-28 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26172</th>\n",
              "      <td>1</td>\n",
              "      <td>6300.0</td>\n",
              "      <td>0</td>\n",
              "      <td>\u0413\u0430\u0440\u0430\u043d\u0442\u0438\u044f \u0431\u0430\u043d\u043a\u043e\u0432\u0441\u043a\u043e\u0439 \u043a\u0430\u0440\u0442\u043e\u0439</td>\n",
              "      <td>2022-02-19 09:55:50</td>\n",
              "      <td>2022-04-16 23:14:35</td>\n",
              "      <td>2022-04-27 15:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>2022-04-28 12:00:00</td>\n",
              "      <td>booking.com</td>\n",
              "      <td>\u041e\u0442\u043c\u0435\u043d\u0430</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26173</th>\n",
              "      <td>1</td>\n",
              "      <td>24600.0</td>\n",
              "      <td>24600</td>\n",
              "      <td>\u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)</td>\n",
              "      <td>2022-08-13 22:35:43</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2022-08-16 15:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>2022-08-17 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439</td>\n",
              "      <td>\u0410\u043f\u0430\u0440\u0442\u0430\u043c\u0435\u043d\u0442\u044b \u0441 2 \u0441\u043f\u0430\u043b\u044c\u043d\u044f\u043c\u0438 \u0441 \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u044b\u043c \u0432\u0445\u043e\u0434\u043e\u043c</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26174 rows \u00d7 14 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       \u041d\u043e\u043c\u0435\u0440\u043e\u0432  \u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c  \u0412\u043d\u0435\u0441\u0435\u043d\u0430 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u0430  \\\n",
              "0            1    25700.0                   0   \n",
              "1            1    24800.0               12400   \n",
              "2            1    25800.0               12900   \n",
              "3            1    10500.0                   0   \n",
              "4            1    28690.0               28690   \n",
              "...        ...        ...                 ...   \n",
              "26169        1    18240.0                9120   \n",
              "26170        1    69600.0               23200   \n",
              "26171        1    55600.0               13900   \n",
              "26172        1     6300.0                   0   \n",
              "26173        1    24600.0               24600   \n",
              "\n",
              "                                           \u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b   \u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f  \\\n",
              "0                                 \u0412\u043d\u0435\u0448\u043d\u044f\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u043e\u043f\u043b\u0430\u0442\u044b 2023-04-20 20:37:30   \n",
              "1      \u041e\u0442\u043b\u043e\u0436\u0435\u043d\u043d\u0430\u044f \u044d\u043b\u0435\u043a\u0442\u0440\u043e\u043d\u043d\u0430\u044f \u043e\u043f\u043b\u0430\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430... 2022-06-18 14:17:02   \n",
              "2                 \u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430) 2022-11-14 22:59:30   \n",
              "3                 \u0412\u043d\u0435\u0448\u043d\u044f\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u043e\u043f\u043b\u0430\u0442\u044b (\u0421 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u043e\u0439) 2023-09-08 15:55:53   \n",
              "4      \u0421\u0438\u0441\u0442\u0435\u043c\u0430 \u0431\u044b\u0441\u0442\u0440\u044b\u0445 \u043f\u043b\u0430\u0442\u0435\u0436\u0435\u0439: \u042d\u043a\u0432\u0430\u0439\u0440\u0438\u043d\u0433 ComfortBoo... 2023-05-20 19:54:13   \n",
              "...                                                  ...                 ...   \n",
              "26169             \u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430) 2023-01-07 17:45:18   \n",
              "26170             \u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430) 2023-06-20 17:54:17   \n",
              "26171             \u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430) 2022-05-08 19:24:05   \n",
              "26172                         \u0413\u0430\u0440\u0430\u043d\u0442\u0438\u044f \u0431\u0430\u043d\u043a\u043e\u0432\u0441\u043a\u043e\u0439 \u043a\u0430\u0440\u0442\u043e\u0439 2022-02-19 09:55:50   \n",
              "26173             \u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430) 2022-08-13 22:35:43   \n",
              "\n",
              "              \u0414\u0430\u0442\u0430 \u043e\u0442\u043c\u0435\u043d\u044b               \u0417\u0430\u0435\u0437\u0434  \u041d\u043e\u0447\u0435\u0439               \u0412\u044b\u0435\u0437\u0434  \\\n",
              "0     2023-04-20 20:39:15 2023-04-28 15:00:00      3 2023-05-01 12:00:00   \n",
              "1                     NaT 2022-07-11 15:00:00      2 2022-07-13 12:00:00   \n",
              "2                     NaT 2022-12-04 15:00:00      2 2022-12-06 12:00:00   \n",
              "3                     NaT 2023-09-18 15:00:00      1 2023-09-19 12:00:00   \n",
              "4                     NaT 2023-05-29 15:00:00      2 2023-05-31 12:00:00   \n",
              "...                   ...                 ...    ...                 ...   \n",
              "26169                 NaT 2023-03-10 15:00:00      2 2023-03-12 12:00:00   \n",
              "26170                 NaT 2023-06-25 15:00:00      3 2023-06-28 12:00:00   \n",
              "26171                 NaT 2022-06-24 15:00:00      4 2022-06-28 12:00:00   \n",
              "26172 2022-04-16 23:14:35 2022-04-27 15:00:00      1 2022-04-28 12:00:00   \n",
              "26173                 NaT 2022-08-16 15:00:00      1 2022-08-17 12:00:00   \n",
              "\n",
              "                 \u0418\u0441\u0442\u043e\u0447\u043d\u0438\u043a \u0421\u0442\u0430\u0442\u0443\u0441 \u0431\u0440\u043e\u043d\u0438  \\\n",
              "0      \u042f\u043d\u0434\u0435\u043a\u0441.\u041f\u0443\u0442\u0435\u0448\u0435\u0441\u0442\u0432\u0438\u044f       \u041e\u0442\u043c\u0435\u043d\u0430   \n",
              "1        \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442     \u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439   \n",
              "2        \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442     \u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439   \n",
              "3       Bronevik.com(new)     \u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439   \n",
              "4        \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442     \u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439   \n",
              "...                   ...          ...   \n",
              "26169    \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442     \u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439   \n",
              "26170    \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442     \u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439   \n",
              "26171    \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442     \u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439   \n",
              "26172         booking.com       \u041e\u0442\u043c\u0435\u043d\u0430   \n",
              "26173    \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442     \u0410\u043a\u0442\u0438\u0432\u043d\u044b\u0439   \n",
              "\n",
              "                                   \u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f \u043d\u043e\u043c\u0435\u0440\u0430  \u0413\u043e\u0441\u0442\u0435\u0439  \u0413\u043e\u0441\u0442\u0438\u043d\u0438\u0446\u0430  \n",
              "0                                  \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb       2          1  \n",
              "1                                  \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb       2          1  \n",
              "2                                    \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0443\u0434\u0438\u044f\u00bb       2          4  \n",
              "3                                  \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb       1          3  \n",
              "4                                      \u041d\u043e\u043c\u0435\u0440 \u00ab\u041b\u044e\u043a\u0441\u00bb       4          1  \n",
              "...                                             ...     ...        ...  \n",
              "26169                              \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb       2          2  \n",
              "26170                                \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0443\u0434\u0438\u044f\u00bb       3          4  \n",
              "26171                              \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb       2          2  \n",
              "26172                              \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb       2          3  \n",
              "26173  \u0410\u043f\u0430\u0440\u0442\u0430\u043c\u0435\u043d\u0442\u044b \u0441 2 \u0441\u043f\u0430\u043b\u044c\u043d\u044f\u043c\u0438 \u0441 \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u044b\u043c \u0432\u0445\u043e\u0434\u043e\u043c       3          1  \n",
              "\n",
              "[26174 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "df_train[\"target\"] = df_train[\"\u0414\u0430\u0442\u0430 \u043e\u0442\u043c\u0435\u043d\u044b\"].apply(lambda x: int(pd.notna(x)))\n",
        "df_train = df_train.drop([\"\u0414\u0430\u0442\u0430 \u043e\u0442\u043c\u0435\u043d\u044b\", \"\u0421\u0442\u0430\u0442\u0443\u0441 \u0431\u0440\u043e\u043d\u0438\"], axis=1)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "df_train"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>\u041d\u043e\u043c\u0435\u0440\u043e\u0432</th>\n",
              "      <th>\u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c</th>\n",
              "      <th>\u0412\u043d\u0435\u0441\u0435\u043d\u0430 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u0430</th>\n",
              "      <th>\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b</th>\n",
              "      <th>\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f</th>\n",
              "      <th>\u0417\u0430\u0435\u0437\u0434</th>\n",
              "      <th>\u041d\u043e\u0447\u0435\u0439</th>\n",
              "      <th>\u0412\u044b\u0435\u0437\u0434</th>\n",
              "      <th>\u0418\u0441\u0442\u043e\u0447\u043d\u0438\u043a</th>\n",
              "      <th>\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f \u043d\u043e\u043c\u0435\u0440\u0430</th>\n",
              "      <th>\u0413\u043e\u0441\u0442\u0435\u0439</th>\n",
              "      <th>\u0413\u043e\u0441\u0442\u0438\u043d\u0438\u0446\u0430</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>25700.0</td>\n",
              "      <td>0</td>\n",
              "      <td>\u0412\u043d\u0435\u0448\u043d\u044f\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u043e\u043f\u043b\u0430\u0442\u044b</td>\n",
              "      <td>2023-04-20 20:37:30</td>\n",
              "      <td>2023-04-28 15:00:00</td>\n",
              "      <td>3</td>\n",
              "      <td>2023-05-01 12:00:00</td>\n",
              "      <td>\u042f\u043d\u0434\u0435\u043a\u0441.\u041f\u0443\u0442\u0435\u0448\u0435\u0441\u0442\u0432\u0438\u044f</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>24800.0</td>\n",
              "      <td>12400</td>\n",
              "      <td>\u041e\u0442\u043b\u043e\u0436\u0435\u043d\u043d\u0430\u044f \u044d\u043b\u0435\u043a\u0442\u0440\u043e\u043d\u043d\u0430\u044f \u043e\u043f\u043b\u0430\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430...</td>\n",
              "      <td>2022-06-18 14:17:02</td>\n",
              "      <td>2022-07-11 15:00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>2022-07-13 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>25800.0</td>\n",
              "      <td>12900</td>\n",
              "      <td>\u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)</td>\n",
              "      <td>2022-11-14 22:59:30</td>\n",
              "      <td>2022-12-04 15:00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>2022-12-06 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0443\u0434\u0438\u044f\u00bb</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>10500.0</td>\n",
              "      <td>0</td>\n",
              "      <td>\u0412\u043d\u0435\u0448\u043d\u044f\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u043e\u043f\u043b\u0430\u0442\u044b (\u0421 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u043e\u0439)</td>\n",
              "      <td>2023-09-08 15:55:53</td>\n",
              "      <td>2023-09-18 15:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>2023-09-19 12:00:00</td>\n",
              "      <td>Bronevik.com(new)</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>28690.0</td>\n",
              "      <td>28690</td>\n",
              "      <td>\u0421\u0438\u0441\u0442\u0435\u043c\u0430 \u0431\u044b\u0441\u0442\u0440\u044b\u0445 \u043f\u043b\u0430\u0442\u0435\u0436\u0435\u0439: \u042d\u043a\u0432\u0430\u0439\u0440\u0438\u043d\u0433 ComfortBoo...</td>\n",
              "      <td>2023-05-20 19:54:13</td>\n",
              "      <td>2023-05-29 15:00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>2023-05-31 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u041b\u044e\u043a\u0441\u00bb</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26169</th>\n",
              "      <td>1</td>\n",
              "      <td>18240.0</td>\n",
              "      <td>9120</td>\n",
              "      <td>\u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)</td>\n",
              "      <td>2023-01-07 17:45:18</td>\n",
              "      <td>2023-03-10 15:00:00</td>\n",
              "      <td>2</td>\n",
              "      <td>2023-03-12 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26170</th>\n",
              "      <td>1</td>\n",
              "      <td>69600.0</td>\n",
              "      <td>23200</td>\n",
              "      <td>\u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)</td>\n",
              "      <td>2023-06-20 17:54:17</td>\n",
              "      <td>2023-06-25 15:00:00</td>\n",
              "      <td>3</td>\n",
              "      <td>2023-06-28 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0443\u0434\u0438\u044f\u00bb</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26171</th>\n",
              "      <td>1</td>\n",
              "      <td>55600.0</td>\n",
              "      <td>13900</td>\n",
              "      <td>\u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)</td>\n",
              "      <td>2022-05-08 19:24:05</td>\n",
              "      <td>2022-06-24 15:00:00</td>\n",
              "      <td>4</td>\n",
              "      <td>2022-06-28 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26172</th>\n",
              "      <td>1</td>\n",
              "      <td>6300.0</td>\n",
              "      <td>0</td>\n",
              "      <td>\u0413\u0430\u0440\u0430\u043d\u0442\u0438\u044f \u0431\u0430\u043d\u043a\u043e\u0432\u0441\u043a\u043e\u0439 \u043a\u0430\u0440\u0442\u043e\u0439</td>\n",
              "      <td>2022-02-19 09:55:50</td>\n",
              "      <td>2022-04-27 15:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>2022-04-28 12:00:00</td>\n",
              "      <td>booking.com</td>\n",
              "      <td>\u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26173</th>\n",
              "      <td>1</td>\n",
              "      <td>24600.0</td>\n",
              "      <td>24600</td>\n",
              "      <td>\u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430)</td>\n",
              "      <td>2022-08-13 22:35:43</td>\n",
              "      <td>2022-08-16 15:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>2022-08-17 12:00:00</td>\n",
              "      <td>\u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442</td>\n",
              "      <td>\u0410\u043f\u0430\u0440\u0442\u0430\u043c\u0435\u043d\u0442\u044b \u0441 2 \u0441\u043f\u0430\u043b\u044c\u043d\u044f\u043c\u0438 \u0441 \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u044b\u043c \u0432\u0445\u043e\u0434\u043e\u043c</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26174 rows \u00d7 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       \u041d\u043e\u043c\u0435\u0440\u043e\u0432  \u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c  \u0412\u043d\u0435\u0441\u0435\u043d\u0430 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u0430  \\\n",
              "0            1    25700.0                   0   \n",
              "1            1    24800.0               12400   \n",
              "2            1    25800.0               12900   \n",
              "3            1    10500.0                   0   \n",
              "4            1    28690.0               28690   \n",
              "...        ...        ...                 ...   \n",
              "26169        1    18240.0                9120   \n",
              "26170        1    69600.0               23200   \n",
              "26171        1    55600.0               13900   \n",
              "26172        1     6300.0                   0   \n",
              "26173        1    24600.0               24600   \n",
              "\n",
              "                                           \u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b   \u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f  \\\n",
              "0                                 \u0412\u043d\u0435\u0448\u043d\u044f\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u043e\u043f\u043b\u0430\u0442\u044b 2023-04-20 20:37:30   \n",
              "1      \u041e\u0442\u043b\u043e\u0436\u0435\u043d\u043d\u0430\u044f \u044d\u043b\u0435\u043a\u0442\u0440\u043e\u043d\u043d\u0430\u044f \u043e\u043f\u043b\u0430\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430... 2022-06-18 14:17:02   \n",
              "2                 \u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430) 2022-11-14 22:59:30   \n",
              "3                 \u0412\u043d\u0435\u0448\u043d\u044f\u044f \u0441\u0438\u0441\u0442\u0435\u043c\u0430 \u043e\u043f\u043b\u0430\u0442\u044b (\u0421 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u043e\u0439) 2023-09-08 15:55:53   \n",
              "4      \u0421\u0438\u0441\u0442\u0435\u043c\u0430 \u0431\u044b\u0441\u0442\u0440\u044b\u0445 \u043f\u043b\u0430\u0442\u0435\u0436\u0435\u0439: \u042d\u043a\u0432\u0430\u0439\u0440\u0438\u043d\u0433 ComfortBoo... 2023-05-20 19:54:13   \n",
              "...                                                  ...                 ...   \n",
              "26169             \u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430) 2023-01-07 17:45:18   \n",
              "26170             \u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430) 2023-06-20 17:54:17   \n",
              "26171             \u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430) 2022-05-08 19:24:05   \n",
              "26172                         \u0413\u0430\u0440\u0430\u043d\u0442\u0438\u044f \u0431\u0430\u043d\u043a\u043e\u0432\u0441\u043a\u043e\u0439 \u043a\u0430\u0440\u0442\u043e\u0439 2022-02-19 09:55:50   \n",
              "26173             \u0411\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430: \u0411\u0430\u043d\u043a \u0420\u043e\u0441\u0441\u0438\u044f (\u0431\u0430\u043d\u043a. \u043a\u0430\u0440\u0442\u0430) 2022-08-13 22:35:43   \n",
              "\n",
              "                    \u0417\u0430\u0435\u0437\u0434  \u041d\u043e\u0447\u0435\u0439               \u0412\u044b\u0435\u0437\u0434            \u0418\u0441\u0442\u043e\u0447\u043d\u0438\u043a  \\\n",
              "0     2023-04-28 15:00:00      3 2023-05-01 12:00:00  \u042f\u043d\u0434\u0435\u043a\u0441.\u041f\u0443\u0442\u0435\u0448\u0435\u0441\u0442\u0432\u0438\u044f   \n",
              "1     2022-07-11 15:00:00      2 2022-07-13 12:00:00    \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442   \n",
              "2     2022-12-04 15:00:00      2 2022-12-06 12:00:00    \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442   \n",
              "3     2023-09-18 15:00:00      1 2023-09-19 12:00:00   Bronevik.com(new)   \n",
              "4     2023-05-29 15:00:00      2 2023-05-31 12:00:00    \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442   \n",
              "...                   ...    ...                 ...                 ...   \n",
              "26169 2023-03-10 15:00:00      2 2023-03-12 12:00:00    \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442   \n",
              "26170 2023-06-25 15:00:00      3 2023-06-28 12:00:00    \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442   \n",
              "26171 2022-06-24 15:00:00      4 2022-06-28 12:00:00    \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442   \n",
              "26172 2022-04-27 15:00:00      1 2022-04-28 12:00:00         booking.com   \n",
              "26173 2022-08-16 15:00:00      1 2022-08-17 12:00:00    \u041e\u0444\u0438\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0439 \u0441\u0430\u0439\u0442   \n",
              "\n",
              "                                   \u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f \u043d\u043e\u043c\u0435\u0440\u0430  \u0413\u043e\u0441\u0442\u0435\u0439  \u0413\u043e\u0441\u0442\u0438\u043d\u0438\u0446\u0430  target  \n",
              "0                                  \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb       2          1       1  \n",
              "1                                  \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb       2          1       0  \n",
              "2                                    \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0443\u0434\u0438\u044f\u00bb       2          4       0  \n",
              "3                                  \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb       1          3       0  \n",
              "4                                      \u041d\u043e\u043c\u0435\u0440 \u00ab\u041b\u044e\u043a\u0441\u00bb       4          1       0  \n",
              "...                                             ...     ...        ...     ...  \n",
              "26169                              \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb       2          2       0  \n",
              "26170                                \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0443\u0434\u0438\u044f\u00bb       3          4       0  \n",
              "26171                              \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb       2          2       0  \n",
              "26172                              \u041d\u043e\u043c\u0435\u0440 \u00ab\u0421\u0442\u0430\u043d\u0434\u0430\u0440\u0442\u00bb       2          3       1  \n",
              "26173  \u0410\u043f\u0430\u0440\u0442\u0430\u043c\u0435\u043d\u0442\u044b \u0441 2 \u0441\u043f\u0430\u043b\u044c\u043d\u044f\u043c\u0438 \u0441 \u043e\u0442\u0434\u0435\u043b\u044c\u043d\u044b\u043c \u0432\u0445\u043e\u0434\u043e\u043c       3          1       0  \n",
              "\n",
              "[26174 rows x 13 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "predictor = TabularPredictor(\n",
        "    label=\"target\", problem_type=\"binary\", eval_metric=\"roc_auc\"\n",
        ").fit(df_train, presets=\"high_quality\", time_limit=560)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20240922_124519\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.1.1\n",
            "Python Version:     3.9.16\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Wed Aug  7 16:19:28 UTC 2024\n",
            "CPU Count:          16\n",
            "Memory Avail:       5.73 GB / 15.49 GB (37.0%)\n",
            "Disk Space Avail:   184.77 GB / 468.09 GB (39.5%)\n",
            "===================================================\n",
            "Presets specified: ['high_quality']\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n",
            "\tYou can avoid this risk by setting `save_bag_folds=True`.\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 140s of the 560s of remaining time (25%).\n",
            "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
            "2024-09-22 15:45:23,162\tINFO worker.py:1743 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8266 \u001b[39m\u001b[22m\n",
            "\t\tContext path: \"AutogluonModels/ag-20240922_124519/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Running DyStack sub-fit ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Beginning AutoGluon training ... Time limit = 135s\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m AutoGluon will save models to \"AutogluonModels/ag-20240922_124519/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Train Data Rows:    23265\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Train Data Columns: 12\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Label Column:       target\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Problem Type:       binary\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Preprocessing data ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Using Feature Generators to preprocess the data ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tAvailable Memory:                    4235.51 MB\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tTrain Data (Original)  Memory Usage: 10.55 MB (0.2% of available memory)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tStage 1 Generators:\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tStage 2 Generators:\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tStage 3 Generators:\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t\tFitting DatetimeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tStage 4 Generators:\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tStage 5 Generators:\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t\t('datetime', []) : 3 | ['\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f', '\u0417\u0430\u0435\u0437\u0434', '\u0412\u044b\u0435\u0437\u0434']\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t\t('float', [])    : 1 | ['\u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c']\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t\t('int', [])      : 5 | ['\u041d\u043e\u043c\u0435\u0440\u043e\u0432', '\u0412\u043d\u0435\u0441\u0435\u043d\u0430 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u0430', '\u041d\u043e\u0447\u0435\u0439', '\u0413\u043e\u0441\u0442\u0435\u0439', '\u0413\u043e\u0441\u0442\u0438\u043d\u0438\u0446\u0430']\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t\t('object', [])   : 3 | ['\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b', '\u0418\u0441\u0442\u043e\u0447\u043d\u0438\u043a', '\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f \u043d\u043e\u043c\u0435\u0440\u0430']\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t\t('category', [])             :  3 | ['\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b', '\u0418\u0441\u0442\u043e\u0447\u043d\u0438\u043a', '\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f \u043d\u043e\u043c\u0435\u0440\u0430']\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t\t('float', [])                :  1 | ['\u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c']\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t\t('int', [])                  :  5 | ['\u041d\u043e\u043c\u0435\u0440\u043e\u0432', '\u0412\u043d\u0435\u0441\u0435\u043d\u0430 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u0430', '\u041d\u043e\u0447\u0435\u0439', '\u0413\u043e\u0441\u0442\u0435\u0439', '\u0413\u043e\u0441\u0442\u0438\u043d\u0438\u0446\u0430']\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t\t('int', ['datetime_as_int']) : 15 | ['\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f', '\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f.year', '\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f.month', '\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f.day', '\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f.dayofweek', ...]\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.2s = Fit runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t12 features in original data used to generate 24 features in processed data.\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tTrain Data (Processed) Memory Usage: 3.80 MB (0.1% of available memory)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Data preprocessing and feature engineering runtime = 0.24s ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m User-specified model hyperparameters to be fit:\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m {\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m }\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting 110 L1 models ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 90.08s of the 135.15s of remaining time.\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.6147\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.02s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.31s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 89.55s of the 134.62s of remaining time.\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.6241\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.02s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.31s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 89.04s of the 134.11s of remaining time.\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.69%)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.8409\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t2.39s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.46s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 84.54s of the 129.61s of remaining time.\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.92%)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.8439\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t1.67s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.16s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 80.55s of the 125.61s of remaining time.\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.8329\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t1.68s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.65s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 77.9s of the 122.96s of remaining time.\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.8341\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t1.44s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.67s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 75.47s of the 120.53s of remaining time.\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.81%)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.8444\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t48.49s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.09s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 24.8s of the 69.86s of remaining time.\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.8235\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t1.18s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.73s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 22.41s of the 67.48s of remaining time.\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.8249\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t1.31s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.76s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 19.86s of the 64.93s of remaining time.\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.96%)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.8432\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t16.67s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.58s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 1.05s of the 46.11s of remaining time.\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.99%)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.8412\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.96s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.14s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 135.16s of the 42.37s of remaining time.\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.353, 'LightGBM_BAG_L1': 0.235, 'CatBoost_BAG_L1': 0.176, 'XGBoost_BAG_L1': 0.118, 'KNeighborsDist_BAG_L1': 0.059, 'RandomForestEntr_BAG_L1': 0.059}\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.8542\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.78s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.0s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting 108 L2 models ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 41.49s of the 41.45s of remaining time.\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.77%)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.8541\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t2.11s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.17s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 37.34s of the 37.3s of remaining time.\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.00%)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.8529\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t2.08s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.1s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 33.09s of the 33.04s of remaining time.\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.8528\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t2.29s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.74s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 29.74s of the 29.69s of remaining time.\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.8554\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t2.61s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.77s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 26.08s of the 26.03s of remaining time.\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.96%)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.8538\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t20.93s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.09s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 2.58s of the 2.54s of remaining time.\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.8587\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t1.39s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.75s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 135.16s of the -0.33s of remaining time.\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tEnsemble Weights: {'ExtraTreesGini_BAG_L2': 0.429, 'RandomForestEntr_BAG_L2': 0.238, 'NeuralNetFastAI_BAG_L1': 0.143, 'RandomForestGini_BAG_L2': 0.095, 'CatBoost_BAG_L1': 0.048, 'LightGBM_BAG_L2': 0.048}\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.8624\t = Validation score   (roc_auc)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t1.1s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.0s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m AutoGluon training complete, total runtime = 136.91s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1307.9 rows/s (2909 batch size)\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.02s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.31s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.02s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.31s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting 1 L1 models ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.71s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting 1 L1 models ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: LightGBM_BAG_L1_FULL ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.31s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t1.68s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.65s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t1.44s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.67s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting 1 L1 models ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: CatBoost_BAG_L1_FULL ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t5.88s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t1.18s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.73s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t1.31s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.76s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting 1 L1 models ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tStopping at the best epoch learned earlier - 7.\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t5.7s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting 1 L1 models ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: XGBoost_BAG_L1_FULL ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.36s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.353, 'LightGBM_BAG_L1': 0.235, 'CatBoost_BAG_L1': 0.176, 'XGBoost_BAG_L1': 0.118, 'KNeighborsDist_BAG_L1': 0.059, 'RandomForestEntr_BAG_L1': 0.059}\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.78s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting 1 L2 models ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: LightGBMXT_BAG_L2_FULL ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.34s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting 1 L2 models ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: LightGBM_BAG_L2_FULL ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.31s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: RandomForestGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t2.29s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.74s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: RandomForestEntr_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t2.61s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.77s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting 1 L2 models ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: CatBoost_BAG_L2_FULL ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t2.4s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: ExtraTreesGini_BAG_L2_FULL | Skipping fit via cloning parent ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t1.39s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t0.75s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Fitting model: WeightedEnsemble_L3_FULL | Skipping fit via cloning parent ...\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \tEnsemble Weights: {'ExtraTreesGini_BAG_L2': 0.429, 'RandomForestEntr_BAG_L2': 0.238, 'NeuralNetFastAI_BAG_L1': 0.143, 'RandomForestGini_BAG_L2': 0.095, 'CatBoost_BAG_L1': 0.048, 'LightGBM_BAG_L2': 0.048}\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m \t1.1s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Updated best model to \"WeightedEnsemble_L3_FULL\" (Previously \"WeightedEnsemble_L3\"). AutoGluon will default to using \"WeightedEnsemble_L3_FULL\" for predict() and predict_proba().\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Refit complete, total runtime = 21.71s ... Best model: \"WeightedEnsemble_L3_FULL\"\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240922_124519/ds_sub_fit/sub_fit_ho\")\n",
            "\u001b[36m(_dystack pid=182245)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
            "Leaderboard on holdout data (DyStack):\n",
            "                           model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0       WeightedEnsemble_L2_FULL       0.868948   0.854213     roc_auc        0.514562            NaN  14.483158                 0.003212                     NaN           0.778295            2       True         12\n",
            "1           CatBoost_BAG_L2_FULL       0.867397   0.853811     roc_auc        1.637561            NaN  21.000439                 0.007598                     NaN           2.401244            2       True         17\n",
            "2         LightGBMXT_BAG_L2_FULL       0.865193   0.854148     roc_auc        1.647162            NaN  18.934924                 0.017199                     NaN           0.335728            2       True         13\n",
            "3       WeightedEnsemble_L3_FULL       0.864850   0.862390     roc_auc        2.061160            NaN  26.290667                 0.004709                     NaN           1.096980            3       True         19\n",
            "4    NeuralNetFastAI_BAG_L1_FULL       0.863025   0.843214     roc_auc        0.059355            NaN   5.695474                 0.059355                     NaN           5.695474            1       True         10\n",
            "5           LightGBM_BAG_L2_FULL       0.861910   0.852941     roc_auc        1.652709            NaN  18.904521                 0.022746                     NaN           0.305326            2       True         14\n",
            "6   RandomForestEntr_BAG_L2_FULL       0.861366   0.855437     roc_auc        1.756578            NaN  21.208107                 0.126615                0.767008           2.608912            2       True         16\n",
            "7         LightGBMXT_BAG_L1_FULL       0.860602   0.840901     roc_auc        0.026852            NaN   0.707469                 0.026852                     NaN           0.707469            1       True          3\n",
            "8           CatBoost_BAG_L1_FULL       0.859961   0.844360     roc_auc        0.010390            NaN   5.882004                 0.010390                     NaN           5.882004            1       True          7\n",
            "9     ExtraTreesGini_BAG_L2_FULL       0.858898   0.858667     roc_auc        1.773401            NaN  19.992721                 0.143437                0.747141           1.393526            2       True         18\n",
            "10  RandomForestGini_BAG_L2_FULL       0.858416   0.852814     roc_auc        1.763654            NaN  20.885923                 0.133690                0.743145           2.286728            2       True         15\n",
            "11          LightGBM_BAG_L1_FULL       0.857149   0.843871     roc_auc        0.021545            NaN   0.307114                 0.021545                     NaN           0.307114            1       True          4\n",
            "12           XGBoost_BAG_L1_FULL       0.853509   0.841231     roc_auc        0.030130            NaN   0.356130                 0.030130                     NaN           0.356130            1       True         11\n",
            "13  RandomForestEntr_BAG_L1_FULL       0.848509   0.834079     roc_auc        0.134729       0.667727   1.444625                 0.134729                0.667727           1.444625            1       True          6\n",
            "14  RandomForestGini_BAG_L1_FULL       0.844389   0.832875     roc_auc        0.152969       0.645974   1.679749                 0.152969                0.645974           1.679749            1       True          5\n",
            "15    ExtraTreesGini_BAG_L1_FULL       0.835792   0.823468     roc_auc        0.282188       0.731004   1.182837                 0.282188                0.731004           1.182837            1       True          8\n",
            "16    ExtraTreesEntr_BAG_L1_FULL       0.833387   0.824918     roc_auc        0.215143       0.755521   1.306180                 0.215143                0.755521           1.306180            1       True          9\n",
            "17    KNeighborsDist_BAG_L1_FULL       0.652852   0.624117     roc_auc        0.255200       0.309212   0.019516                 0.255200                0.309212           0.019516            1       True          2\n",
            "18    KNeighborsUnif_BAG_L1_FULL       0.650880   0.614675     roc_auc        0.441462       0.310453   0.018098                 0.441462                0.310453           0.018098            1       True          1\n",
            "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
            "\t167s\t = DyStack   runtime |\t393s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=0.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
            "Beginning AutoGluon training ... Time limit = 393s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20240922_124519\"\n",
            "Train Data Rows:    26174\n",
            "Train Data Columns: 12\n",
            "Label Column:       target\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    4286.83 MB\n",
            "\tTrain Data (Original)  Memory Usage: 15.51 MB (0.4% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting DatetimeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('datetime', []) : 3 | ['\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f', '\u0417\u0430\u0435\u0437\u0434', '\u0412\u044b\u0435\u0437\u0434']\n",
            "\t\t('float', [])    : 1 | ['\u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c']\n",
            "\t\t('int', [])      : 5 | ['\u041d\u043e\u043c\u0435\u0440\u043e\u0432', '\u0412\u043d\u0435\u0441\u0435\u043d\u0430 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u0430', '\u041d\u043e\u0447\u0435\u0439', '\u0413\u043e\u0441\u0442\u0435\u0439', '\u0413\u043e\u0441\u0442\u0438\u043d\u0438\u0446\u0430']\n",
            "\t\t('object', [])   : 3 | ['\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b', '\u0418\u0441\u0442\u043e\u0447\u043d\u0438\u043a', '\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f \u043d\u043e\u043c\u0435\u0440\u0430']\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])             :  3 | ['\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b', '\u0418\u0441\u0442\u043e\u0447\u043d\u0438\u043a', '\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f \u043d\u043e\u043c\u0435\u0440\u0430']\n",
            "\t\t('float', [])                :  1 | ['\u0421\u0442\u043e\u0438\u043c\u043e\u0441\u0442\u044c']\n",
            "\t\t('int', [])                  :  5 | ['\u041d\u043e\u043c\u0435\u0440\u043e\u0432', '\u0412\u043d\u0435\u0441\u0435\u043d\u0430 \u043f\u0440\u0435\u0434\u043e\u043f\u043b\u0430\u0442\u0430', '\u041d\u043e\u0447\u0435\u0439', '\u0413\u043e\u0441\u0442\u0435\u0439', '\u0413\u043e\u0441\u0442\u0438\u043d\u0438\u0446\u0430']\n",
            "\t\t('int', ['datetime_as_int']) : 15 | ['\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f', '\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f.year', '\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f.month', '\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f.day', '\u0414\u0430\u0442\u0430 \u0431\u0440\u043e\u043d\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u044f.dayofweek', ...]\n",
            "\t0.4s = Fit runtime\n",
            "\t12 features in original data used to generate 24 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 4.27 MB (0.1% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.4s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
            "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 110 L1 models ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 392.43s of the 392.42s of remaining time.\n",
            "\t0.6232\t = Validation score   (roc_auc)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.56s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 391.58s of the 391.57s of remaining time.\n",
            "\t0.6301\t = Validation score   (roc_auc)\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.53s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 390.87s of the 390.85s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.62%)\n",
            "\t0.8437\t = Validation score   (roc_auc)\n",
            "\t2.81s\t = Training   runtime\n",
            "\t0.47s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 385.69s of the 385.68s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.70%)\n",
            "\t0.8465\t = Validation score   (roc_auc)\n",
            "\t1.77s\t = Training   runtime\n",
            "\t0.16s\t = Validation runtime\n",
            "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 381.62s of the 381.61s of remaining time.\n",
            "\t0.8334\t = Validation score   (roc_auc)\n",
            "\t1.71s\t = Training   runtime\n",
            "\t0.72s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 378.82s of the 378.81s of remaining time.\n",
            "\t0.8349\t = Validation score   (roc_auc)\n",
            "\t1.54s\t = Training   runtime\n",
            "\t0.7s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 376.22s of the 376.21s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.71%)\n",
            "\t0.8478\t = Validation score   (roc_auc)\n",
            "\t48.29s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 326.28s of the 326.26s of remaining time.\n",
            "\t0.8265\t = Validation score   (roc_auc)\n",
            "\t1.29s\t = Training   runtime\n",
            "\t0.77s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 323.71s of the 323.69s of remaining time.\n",
            "\t0.8283\t = Validation score   (roc_auc)\n",
            "\t1.22s\t = Training   runtime\n",
            "\t0.79s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 321.18s of the 321.17s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.92%)\n",
            "\t0.8469\t = Validation score   (roc_auc)\n",
            "\t46.48s\t = Training   runtime\n",
            "\t0.63s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1 ... Training model for up to 272.41s of the 272.39s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.03%)\n",
            "\t0.847\t = Validation score   (roc_auc)\n",
            "\t2.41s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 267.74s of the 267.72s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.56%)\n",
            "\t0.8364\t = Validation score   (roc_auc)\n",
            "\t60.07s\t = Training   runtime\n",
            "\t1.63s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 205.36s of the 205.35s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.91%)\n",
            "\t0.8431\t = Validation score   (roc_auc)\n",
            "\t3.11s\t = Training   runtime\n",
            "\t0.27s\t = Validation runtime\n",
            "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 199.88s of the 199.87s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.75%)\n",
            "\t0.8478\t = Validation score   (roc_auc)\n",
            "\t34.04s\t = Training   runtime\n",
            "\t0.09s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 163.59s of the 163.57s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.44%)\n",
            "\t0.8502\t = Validation score   (roc_auc)\n",
            "\t63.68s\t = Training   runtime\n",
            "\t1.43s\t = Validation runtime\n",
            "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 97.61s of the 97.6s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.62%)\n",
            "\t0.8476\t = Validation score   (roc_auc)\n",
            "\t4.8s\t = Training   runtime\n",
            "\t1.17s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 90.25s of the 90.24s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.82%)\n",
            "\t0.8442\t = Validation score   (roc_auc)\n",
            "\t74.2s\t = Training   runtime\n",
            "\t0.95s\t = Validation runtime\n",
            "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 13.93s of the 13.91s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=1.83%)\n",
            "\t0.8393\t = Validation score   (roc_auc)\n",
            "\t11.23s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 0.04s of remaining time.\n",
            "\tEnsemble Weights: {'NeuralNetTorch_r79_BAG_L1': 0.294, 'NeuralNetFastAI_BAG_L1': 0.176, 'CatBoost_r177_BAG_L1': 0.118, 'NeuralNetFastAI_r191_BAG_L1': 0.118, 'KNeighborsDist_BAG_L1': 0.059, 'LightGBM_BAG_L1': 0.059, 'CatBoost_BAG_L1': 0.059, 'XGBoost_BAG_L1': 0.059, 'LightGBMLarge_BAG_L1': 0.059}\n",
            "\t0.8607\t = Validation score   (roc_auc)\n",
            "\t1.44s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 394.38s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 850.8 rows/s (3272 batch size)\n",
            "Automatically performing refit_full as a post-fit operation (due to `.fit(..., refit_full=True)`\n",
            "Refitting models via `predictor.refit_full` using all of the data (combined train and validation)...\n",
            "\tModels trained in this way will have the suffix \"_FULL\" and have NaN validation score.\n",
            "\tThis process is not bound by time_limit, but should take less time than the original `predictor.fit` call.\n",
            "\tTo learn more, refer to the `.refit_full` method docstring which explains how \"_FULL\" models differ from normal models.\n",
            "Fitting model: KNeighborsUnif_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.56s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t0.02s\t = Training   runtime\n",
            "\t0.53s\t = Validation runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBMXT_BAG_L1_FULL ...\n",
            "\t0.72s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBM_BAG_L1_FULL ...\n",
            "\t0.37s\t = Training   runtime\n",
            "Fitting model: RandomForestGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t1.71s\t = Training   runtime\n",
            "\t0.72s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t1.54s\t = Training   runtime\n",
            "\t0.7s\t = Validation runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: CatBoost_BAG_L1_FULL ...\n",
            "\t5.64s\t = Training   runtime\n",
            "Fitting model: ExtraTreesGini_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t1.29s\t = Training   runtime\n",
            "\t0.77s\t = Validation runtime\n",
            "Fitting model: ExtraTreesEntr_BAG_L1_FULL | Skipping fit via cloning parent ...\n",
            "\t1.22s\t = Training   runtime\n",
            "\t0.79s\t = Validation runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: NeuralNetFastAI_BAG_L1_FULL ...\n",
            "\tStopping at the best epoch learned earlier - 14.\n",
            "\t12.1s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: XGBoost_BAG_L1_FULL ...\n",
            "\t0.35s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: NeuralNetTorch_BAG_L1_FULL ...\n",
            "\t18.32s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBMLarge_BAG_L1_FULL ...\n",
            "\t0.69s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: CatBoost_r177_BAG_L1_FULL ...\n",
            "\t3.62s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: NeuralNetTorch_r79_BAG_L1_FULL ...\n",
            "\t19.78s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: LightGBM_r131_BAG_L1_FULL ...\n",
            "\t1.19s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: NeuralNetFastAI_r191_BAG_L1_FULL ...\n",
            "\tStopping at the best epoch learned earlier - 16.\n",
            "\t19.89s\t = Training   runtime\n",
            "Fitting 1 L1 models ...\n",
            "Fitting model: CatBoost_r9_BAG_L1_FULL ...\n",
            "\t2.33s\t = Training   runtime\n",
            "Fitting model: WeightedEnsemble_L2_FULL | Skipping fit via cloning parent ...\n",
            "\tEnsemble Weights: {'NeuralNetTorch_r79_BAG_L1': 0.294, 'NeuralNetFastAI_BAG_L1': 0.176, 'CatBoost_r177_BAG_L1': 0.118, 'NeuralNetFastAI_r191_BAG_L1': 0.118, 'KNeighborsDist_BAG_L1': 0.059, 'LightGBM_BAG_L1': 0.059, 'CatBoost_BAG_L1': 0.059, 'XGBoost_BAG_L1': 0.059, 'LightGBMLarge_BAG_L1': 0.059}\n",
            "\t1.44s\t = Training   runtime\n",
            "Updated best model to \"WeightedEnsemble_L2_FULL\" (Previously \"WeightedEnsemble_L2\"). AutoGluon will default to using \"WeightedEnsemble_L2_FULL\" for predict() and predict_proba().\n",
            "Refit complete, total runtime = 89.12s ... Best model: \"WeightedEnsemble_L2_FULL\"\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240922_124519\")\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "predictions = predictor.predict_proba(df_test)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "predictions"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.913458</td>\n",
              "      <td>0.086542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.900119</td>\n",
              "      <td>0.099881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.946630</td>\n",
              "      <td>0.053370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.915985</td>\n",
              "      <td>0.084015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.855043</td>\n",
              "      <td>0.144957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11213</th>\n",
              "      <td>0.900134</td>\n",
              "      <td>0.099866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11214</th>\n",
              "      <td>0.784633</td>\n",
              "      <td>0.215367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11215</th>\n",
              "      <td>0.946576</td>\n",
              "      <td>0.053424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11216</th>\n",
              "      <td>0.946897</td>\n",
              "      <td>0.053103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11217</th>\n",
              "      <td>0.754628</td>\n",
              "      <td>0.245372</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11218 rows \u00d7 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              0         1\n",
              "0      0.913458  0.086542\n",
              "1      0.900119  0.099881\n",
              "2      0.946630  0.053370\n",
              "3      0.915985  0.084015\n",
              "4      0.855043  0.144957\n",
              "...         ...       ...\n",
              "11213  0.900134  0.099866\n",
              "11214  0.784633  0.215367\n",
              "11215  0.946576  0.053424\n",
              "11216  0.946897  0.053103\n",
              "11217  0.754628  0.245372\n",
              "\n",
              "[11218 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "predictions[1].to_csv(\"autogluon_on_processed_data_2.csv\", index=False, header=False)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "error",
          "ename": "",
          "evalue": "",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "submissiom.to_csv(\"4x_blending.csv\", index=False, header=False)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "X_train = df_train.drop(\"target\", axis=1)\n",
        "y_train = df_train[\"target\"]"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# for forests\n",
        "# encoder = OneHotEncoder(drop=\"first\", sparse_output=False)\n",
        "# cat_columns = X_train.select_dtypes(include=[\"object\"]).columns\n",
        "# X_train_forest = pd.concat(\n",
        "#     [\n",
        "#         X_train.drop(cat_columns, axis=1),\n",
        "#         pd.DataFrame(\n",
        "#             encoder.fit_transform(X_train[cat_columns]),\n",
        "#             columns=encoder.get_feature_names_out(),\n",
        "#         ),\n",
        "#     ],\n",
        "#     axis=1,\n",
        "# )\n",
        "# df_test_forest = pd.concat(\n",
        "#     [\n",
        "#         df_test.drop(cat_columns, axis=1),\n",
        "#         pd.DataFrame(\n",
        "#             encoder.transform(df_test[cat_columns]),\n",
        "#             columns=encoder.get_feature_names_out(),\n",
        "#         ),\n",
        "#     ],\n",
        "#     axis=1,\n",
        "# )\n",
        "\n",
        "# # for lgbm\n",
        "# X_train_lgbm = X_train.copy()\n",
        "# df_test_lgbm = df_test.copy()\n",
        "# for cat in cat_columns:\n",
        "#     X_train_lgbm[cat] = X_train_lgbm[cat].astype(\"category\")\n",
        "#     df_test_lgbm[cat] = df_test_lgbm[cat].astype(\"category\")"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "SEARCH_BEST_PARAMS = True\n",
        "N_TRIALS = 30\n",
        "CAT_FEATURES = [\"\u0421\u043f\u043e\u0441\u043e\u0431 \u043e\u043f\u043b\u0430\u0442\u044b\", \"\u0418\u0441\u0442\u043e\u0447\u043d\u0438\u043a\", \"\u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u044f \u043d\u043e\u043c\u0435\u0440\u0430\"]\n",
        "RANDOM_SEED = 42\n",
        "EVAL_METRIC = \"AUC\"\n",
        "EARLY_STOPPING = 50"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# from catboost import CatBoostRegressor, Pool, EShapCalcType, EFeaturesSelectionAlgorithm\n",
        "\n",
        "# # Stratified train-test split\n",
        "# X_train_select, X_test_select, y_train_select, y_test_select = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=42)\n",
        "\n",
        "# # Define and fit CatBoost model\n",
        "# model = CatBoostClassifier(\n",
        "#         cat_features=CAT_FEATURES,\n",
        "#         verbose=0,\n",
        "#         eval_metric=EVAL_METRIC,\n",
        "#         early_stopping_rounds=EARLY_STOPPING,\n",
        "#     )\n",
        "\n",
        "# # Perform feature selection\n",
        "# selected_features = model.select_features(\n",
        "#     X_train_select, y_train_select,\n",
        "#     eval_set=(X_test_select,y_test_select),\n",
        "#     features_for_select=X_train.columns.to_list(),  # selects from all features (indexing starts from 0)\n",
        "#     num_features_to_select=15,   # number of features you want to keep\n",
        "#     steps=30,                    # steps to remove features\n",
        "#     verbose=True,\n",
        "# )"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# X_train = X_train.drop(selected_features[\"eliminated_features_names\"], axis=1)\n",
        "# df_test = df_test.drop(selected_features[\"eliminated_features_names\"], axis=1)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# catboost is good on defaults\n",
        "models_list = []\n",
        "scores_list = []\n",
        "y_pred = np.zeros(df_test.shape[0])\n",
        "splitter = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
        "for i, (train_index, test_index) in enumerate(splitter.split(X_train, y_train)):\n",
        "    X_fold_train, y_fold_train = X_train.iloc[train_index], y_train.iloc[train_index]\n",
        "    X_fold_test, y_fold_test = X_train.iloc[test_index], y_train.iloc[test_index]\n",
        "\n",
        "    model = CatBoostClassifier(\n",
        "        cat_features=CAT_FEATURES,\n",
        "        verbose=0,\n",
        "        eval_metric=EVAL_METRIC,\n",
        "        early_stopping_rounds=EARLY_STOPPING,\n",
        "    )\n",
        "\n",
        "    model.fit(X_fold_train, y_fold_train, eval_set=(X_fold_test, y_fold_test))\n",
        "\n",
        "    preds = model.predict_proba(X_fold_test)[:, 1]\n",
        "    score = roc_auc_score(y_fold_test, preds)\n",
        "\n",
        "    models_list.append(model)\n",
        "    scores_list.append(score)\n",
        "\n",
        "np.mean(scores_list), np.std(scores_list)"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8627034580046269, 0.014790056605410043)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "y_pred = np.zeros(df_test.shape[0])\n",
        "for model in models_list:\n",
        "    y_pred += model.predict_proba(df_test)[:, 1]\n",
        "\n",
        "y_pred = y_pred / len(models_list)\n",
        "\n",
        "submissiom = pd.DataFrame(y_pred)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "submissiom[0] = submissiom[0].apply(lambda x: int(x > 0.5))"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "submissiom.value_counts()"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0\n",
              "0    10029\n",
              "1     1189\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "submissiom.to_csv(\"catboost_only_binary.csv\", index=False, header=False)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "if SEARCH_BEST_PARAMS:\n",
        "    study = optuna.create_study(\n",
        "        direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
        "    )\n",
        "    study.optimize(\n",
        "        lambda trial: objective(trial, X_train_lgbm, y_train, \"LightGBM\"),\n",
        "        n_trials=N_TRIALS - 15,\n",
        "        show_progress_bar=True,\n",
        "    )"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-21 21:56:14,953] A new study created in memory with name: no-name-0b654a55-3330-455c-949a-2538d7371036\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a43a822952e431d93bad4f0b30e2132",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2024-09-21 21:58:19,366] Trial 0 finished with value: 0.8583994683558867 and parameters: {'boosting_type': 'dart', 'num_leaves': 64, 'max_depth': 4, 'learning_rate': 0.055238410897498764, 'feature_fraction': 0.4348501673009197, 'lambda_l1': 8.661895281603577, 'lambda_l2': 6.011549002420345, 'min_child_samples': 72, 'bagging_fraction': 0.41235069657748147, 'bagging_freq': 7}. Best is trial 0 with value: 0.8583994683558867.\n",
            "[I 2024-09-21 21:58:25,624] Trial 1 finished with value: 0.8600574020899071 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 26, 'max_depth': 5, 'learning_rate': 0.16217936517334897, 'feature_fraction': 0.6591670111852694, 'lambda_l1': 2.913000172840221, 'lambda_l2': 6.118917094329073, 'min_child_samples': 18, 'bagging_fraction': 0.5752867891211308, 'bagging_freq': 3}. Best is trial 1 with value: 0.8600574020899071.\n",
            "[I 2024-09-21 21:59:55,914] Trial 2 finished with value: 0.8602790611151823 and parameters: {'boosting_type': 'dart', 'num_leaves': 56, 'max_depth': 7, 'learning_rate': 0.02347061968879934, 'feature_fraction': 0.764526911140863, 'lambda_l1': 1.706070712749228, 'lambda_l2': 0.65145087825981, 'min_child_samples': 96, 'bagging_fraction': 0.9793792198447356, 'bagging_freq': 6}. Best is trial 2 with value: 0.8602790611151823.\n",
            "[I 2024-09-21 21:59:59,857] Trial 3 finished with value: 0.8594360254624146 and parameters: {'boosting_type': 'goss', 'num_leaves': 50, 'max_depth': 3, 'learning_rate': 0.15360130393226834, 'feature_fraction': 0.42063311266913106, 'lambda_l1': 9.093294700385743, 'lambda_l2': 2.588541036018569, 'min_child_samples': 68}. Best is trial 2 with value: 0.8602790611151823.\n",
            "[I 2024-09-21 22:00:04,014] Trial 4 finished with value: 0.8581869988965772 and parameters: {'boosting_type': 'goss', 'num_leaves': 26, 'max_depth': 10, 'learning_rate': 0.2347885187747232, 'feature_fraction': 0.9636993649385135, 'lambda_l1': 8.94837867692606, 'lambda_l2': 5.979401888132041, 'min_child_samples': 93}. Best is trial 2 with value: 0.8602790611151823.\n",
            "[I 2024-09-21 22:01:33,091] Trial 5 finished with value: 0.8538169726865881 and parameters: {'boosting_type': 'dart', 'num_leaves': 39, 'max_depth': 6, 'learning_rate': 0.08869121921442981, 'feature_fraction': 0.8972425054911576, 'lambda_l1': 3.5681765136091994, 'lambda_l2': 2.8100641623641205, 'min_child_samples': 57, 'bagging_fraction': 0.4845545349848576, 'bagging_freq': 6}. Best is trial 2 with value: 0.8602790611151823.\n",
            "[I 2024-09-21 22:02:19,464] Trial 6 finished with value: 0.8562996773763316 and parameters: {'boosting_type': 'dart', 'num_leaves': 28, 'max_depth': 3, 'learning_rate': 0.2464838142519019, 'feature_fraction': 0.8241144063085704, 'lambda_l1': 7.290342673241833, 'lambda_l2': 7.712932196512773, 'min_child_samples': 12, 'bagging_fraction': 0.6150794371265635, 'bagging_freq': 1}. Best is trial 2 with value: 0.8602790611151823.\n",
            "[I 2024-09-21 22:02:22,471] Trial 7 finished with value: 0.858397058069019 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 15, 'max_depth': 5, 'learning_rate': 0.10430316338775664, 'feature_fraction': 0.8377637070028385, 'lambda_l1': 6.375937156080776, 'lambda_l2': 8.872240213020689, 'min_child_samples': 50, 'bagging_fraction': 0.471756547562981, 'bagging_freq': 5}. Best is trial 2 with value: 0.8602790611151823.\n",
            "[I 2024-09-21 22:02:25,386] Trial 8 finished with value: 0.8594464355057202 and parameters: {'boosting_type': 'goss', 'num_leaves': 54, 'max_depth': 7, 'learning_rate': 0.1339868953239794, 'feature_fraction': 0.4152514760464571, 'lambda_l1': 1.0798063785060512, 'lambda_l2': 0.3152604276816558, 'min_child_samples': 66}. Best is trial 2 with value: 0.8602790611151823.\n",
            "[I 2024-09-21 22:02:27,962] Trial 9 finished with value: 0.8575598231428824 and parameters: {'boosting_type': 'goss', 'num_leaves': 32, 'max_depth': 6, 'learning_rate': 0.2291098301774841, 'feature_fraction': 0.5372788992949735, 'lambda_l1': 0.7707221183781011, 'lambda_l2': 2.8982247776847667, 'min_child_samples': 20}. Best is trial 2 with value: 0.8602790611151823.\n",
            "[I 2024-09-21 22:03:44,053] Trial 10 finished with value: 0.8605477509234868 and parameters: {'boosting_type': 'dart', 'num_leaves': 85, 'max_depth': 9, 'learning_rate': 0.015208943928297636, 'feature_fraction': 0.7015187306048778, 'lambda_l1': 3.9790804967476054, 'lambda_l2': 0.15256787628653778, 'min_child_samples': 98, 'bagging_fraction': 0.9821328682808784, 'bagging_freq': 4}. Best is trial 10 with value: 0.8605477509234868.\n",
            "[I 2024-09-21 22:05:04,391] Trial 11 finished with value: 0.8604799482261521 and parameters: {'boosting_type': 'dart', 'num_leaves': 93, 'max_depth': 9, 'learning_rate': 0.01835519874941342, 'feature_fraction': 0.6999731382848587, 'lambda_l1': 4.326099430193638, 'lambda_l2': 0.10934759077830591, 'min_child_samples': 100, 'bagging_fraction': 0.978623168800851, 'bagging_freq': 4}. Best is trial 10 with value: 0.8605477509234868.\n",
            "[I 2024-09-21 22:06:03,775] Trial 12 finished with value: 0.8599287151468286 and parameters: {'boosting_type': 'dart', 'num_leaves': 97, 'max_depth': 9, 'learning_rate': 0.017318055252790773, 'feature_fraction': 0.6446713618171314, 'lambda_l1': 4.88883946795536, 'lambda_l2': 1.4990721854763356, 'min_child_samples': 100, 'bagging_fraction': 0.9897600790985702, 'bagging_freq': 3}. Best is trial 10 with value: 0.8605477509234868.\n",
            "[I 2024-09-21 22:07:43,277] Trial 13 finished with value: 0.8561827462515431 and parameters: {'boosting_type': 'dart', 'num_leaves': 95, 'max_depth': 9, 'learning_rate': 0.06567448992833927, 'feature_fraction': 0.5850453461001829, 'lambda_l1': 4.847390921526337, 'lambda_l2': 0.13239001686236396, 'min_child_samples': 78, 'bagging_fraction': 0.83081875877721, 'bagging_freq': 4}. Best is trial 10 with value: 0.8605477509234868.\n",
            "[I 2024-09-21 22:09:28,377] Trial 14 finished with value: 0.8611098264769588 and parameters: {'boosting_type': 'dart', 'num_leaves': 80, 'max_depth': 8, 'learning_rate': 0.02353980066877352, 'feature_fraction': 0.7146404372369975, 'lambda_l1': 2.9294801014827625, 'lambda_l2': 4.301118582479693, 'min_child_samples': 85, 'bagging_fraction': 0.8207939948373919, 'bagging_freq': 3}. Best is trial 14 with value: 0.8611098264769588.\n",
            "[I 2024-09-21 22:12:00,761] Trial 15 finished with value: 0.8392997788589371 and parameters: {'boosting_type': 'dart', 'num_leaves': 78, 'max_depth': 8, 'learning_rate': 0.2934072750225726, 'feature_fraction': 0.7626791568432525, 'lambda_l1': 2.5725681807901704, 'lambda_l2': 4.59725314615027, 'min_child_samples': 84, 'bagging_fraction': 0.796359547497075, 'bagging_freq': 2}. Best is trial 14 with value: 0.8611098264769588.\n",
            "[I 2024-09-21 22:12:12,144] Trial 16 finished with value: 0.8603689116058026 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 78, 'max_depth': 10, 'learning_rate': 0.05591835971230835, 'feature_fraction': 0.5597734008162901, 'lambda_l1': 6.25382769995306, 'lambda_l2': 4.156391424987822, 'min_child_samples': 40, 'bagging_fraction': 0.8409778830855048, 'bagging_freq': 3}. Best is trial 14 with value: 0.8611098264769588.\n",
            "[I 2024-09-21 22:14:15,511] Trial 17 finished with value: 0.846107345777145 and parameters: {'boosting_type': 'dart', 'num_leaves': 81, 'max_depth': 8, 'learning_rate': 0.11459696713161138, 'feature_fraction': 0.7457222283591181, 'lambda_l1': 0.014539524404754367, 'lambda_l2': 1.8137262231653253, 'min_child_samples': 86, 'bagging_fraction': 0.7366888821986693, 'bagging_freq': 1}. Best is trial 14 with value: 0.8611098264769588.\n",
            "[I 2024-09-21 22:16:23,545] Trial 18 finished with value: 0.8583889960715435 and parameters: {'boosting_type': 'dart', 'num_leaves': 68, 'max_depth': 8, 'learning_rate': 0.04549022989003261, 'feature_fraction': 0.6276835368761836, 'lambda_l1': 2.422914384286307, 'lambda_l2': 9.751457281064663, 'min_child_samples': 39, 'bagging_fraction': 0.885859368874199, 'bagging_freq': 5}. Best is trial 14 with value: 0.8611098264769588.\n",
            "[I 2024-09-21 22:16:28,661] Trial 19 finished with value: 0.8598606487078457 and parameters: {'boosting_type': 'gbdt', 'num_leaves': 86, 'max_depth': 10, 'learning_rate': 0.1857065514815792, 'feature_fraction': 0.5187167083556798, 'lambda_l1': 3.9771086646740557, 'lambda_l2': 3.9564006318932816, 'min_child_samples': 84, 'bagging_fraction': 0.9147570034736743, 'bagging_freq': 2}. Best is trial 14 with value: 0.8611098264769588.\n",
            "[I 2024-09-21 22:17:58,729] Trial 20 finished with value: 0.8568295205835834 and parameters: {'boosting_type': 'dart', 'num_leaves': 68, 'max_depth': 8, 'learning_rate': 0.08212319869612082, 'feature_fraction': 0.8312437199753491, 'lambda_l1': 5.575954218692617, 'lambda_l2': 7.103425450083497, 'min_child_samples': 59, 'bagging_fraction': 0.6810225789156616, 'bagging_freq': 5}. Best is trial 14 with value: 0.8611098264769588.\n",
            "[I 2024-09-21 22:19:09,002] Trial 21 finished with value: 0.8607329760142297 and parameters: {'boosting_type': 'dart', 'num_leaves': 88, 'max_depth': 9, 'learning_rate': 0.015306699513039401, 'feature_fraction': 0.7055455506771616, 'lambda_l1': 3.4667798146950264, 'lambda_l2': 1.3225506032930974, 'min_child_samples': 100, 'bagging_fraction': 0.9337338516796632, 'bagging_freq': 4}. Best is trial 14 with value: 0.8611098264769588.\n",
            "[I 2024-09-21 22:20:19,059] Trial 22 finished with value: 0.8590356790958531 and parameters: {'boosting_type': 'dart', 'num_leaves': 87, 'max_depth': 9, 'learning_rate': 0.010555186052950067, 'feature_fraction': 0.709620671906576, 'lambda_l1': 3.3187817333903604, 'lambda_l2': 1.5786083017266619, 'min_child_samples': 89, 'bagging_fraction': 0.9098586758773998, 'bagging_freq': 4}. Best is trial 14 with value: 0.8611098264769588.\n",
            "[I 2024-09-21 22:23:06,123] Trial 23 finished with value: 0.8589940495707855 and parameters: {'boosting_type': 'dart', 'num_leaves': 72, 'max_depth': 7, 'learning_rate': 0.038047890619505226, 'feature_fraction': 0.7162298179199247, 'lambda_l1': 1.9488599372538746, 'lambda_l2': 1.1406356013857484, 'min_child_samples': 77, 'bagging_fraction': 0.76064836769509, 'bagging_freq': 4}. Best is trial 14 with value: 0.8611098264769588.\n",
            "[I 2024-09-21 22:25:55,086] Trial 24 finished with value: 0.8541357752246934 and parameters: {'boosting_type': 'dart', 'num_leaves': 89, 'max_depth': 9, 'learning_rate': 0.08490995469636389, 'feature_fraction': 0.7945462032341207, 'lambda_l1': 3.957293062523805, 'lambda_l2': 3.1875563971224787, 'min_child_samples': 92, 'bagging_fraction': 0.9255573053677162, 'bagging_freq': 3}. Best is trial 14 with value: 0.8611098264769588.\n",
            "[W 2024-09-21 22:27:53,638] Trial 25 failed with parameters: {'boosting_type': 'dart', 'num_leaves': 98, 'max_depth': 8, 'learning_rate': 0.03752173169812073, 'feature_fraction': 0.6100951606786418, 'lambda_l1': 5.773976183790456, 'lambda_l2': 5.056254561425493, 'min_child_samples': 81, 'bagging_fraction': 0.8650872197386723, 'bagging_freq': 2} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/seara/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"/tmp/ipykernel_1223169/2989494471.py\", line 6, in <lambda>\n",
            "    lambda trial: objective(trial, X_train_lgbm, y_train, \"LightGBM\"),\n",
            "  File \"/home/seara/Desktop/Github/HSE_hack/fisting.py\", line 185, in objective\n",
            "    model, y_pred = model_types_dict[model_type](trial, train, val, **kwargs)\n",
            "  File \"/home/seara/Desktop/Github/HSE_hack/fisting.py\", line 97, in fit_lgbm\n",
            "    model.fit(\n",
            "  File \"/home/seara/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 1284, in fit\n",
            "    super().fit(\n",
            "  File \"/home/seara/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/lightgbm/sklearn.py\", line 955, in fit\n",
            "    self._Booster = train(\n",
            "  File \"/home/seara/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/lightgbm/engine.py\", line 307, in train\n",
            "    booster.update(fobj=fobj)\n",
            "  File \"/home/seara/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/lightgbm/basic.py\", line 4136, in update\n",
            "    _LIB.LGBM_BoosterUpdateOneIter(\n",
            "KeyboardInterrupt\n",
            "[W 2024-09-21 22:27:53,640] Trial 25 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m SEARCH_BEST_PARAMS:\n\u001b[1;32m      2\u001b[0m     study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m      3\u001b[0m         direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m, sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39mRANDOM_SEED)\n\u001b[1;32m      4\u001b[0m     )\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_lgbm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLightGBM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_TRIALS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
            "Cell \u001b[0;32mIn[13], line 6\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m SEARCH_BEST_PARAMS:\n\u001b[1;32m      2\u001b[0m     study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m      3\u001b[0m         direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m, sampler\u001b[38;5;241m=\u001b[39moptuna\u001b[38;5;241m.\u001b[39msamplers\u001b[38;5;241m.\u001b[39mTPESampler(seed\u001b[38;5;241m=\u001b[39mRANDOM_SEED)\n\u001b[1;32m      4\u001b[0m     )\n\u001b[1;32m      5\u001b[0m     study\u001b[38;5;241m.\u001b[39moptimize(\n\u001b[0;32m----> 6\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m trial: \u001b[43mobjective\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_lgbm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLightGBM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      7\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mN_TRIALS,\n\u001b[1;32m      8\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m     )\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/fisting.py:185\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial, X_train, y_train, model_type, return_models, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m train \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39miloc[train_index], y_train\u001b[38;5;241m.\u001b[39miloc[train_index]\n\u001b[1;32m    183\u001b[0m val \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39miloc[val_index], y_train\u001b[38;5;241m.\u001b[39miloc[val_index]\n\u001b[0;32m--> 185\u001b[0m model, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_types_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m scores\u001b[38;5;241m.\u001b[39mappend(roc_auc_score(val[\u001b[38;5;241m1\u001b[39m], y_pred[:, \u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    187\u001b[0m models\u001b[38;5;241m.\u001b[39mappend(model)\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/fisting.py:97\u001b[0m, in \u001b[0;36mfit_lgbm\u001b[0;34m(trial, train, val)\u001b[0m\n\u001b[1;32m     87\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mearly_stopping_round\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[1;32m     89\u001b[0m model \u001b[38;5;241m=\u001b[39m LGBMClassifier(\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m     91\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m     random_state\u001b[38;5;241m=\u001b[39mRANDOM_SEED,\n\u001b[1;32m     95\u001b[0m )\n\u001b[0;32m---> 97\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEVAL_METRIC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCAT_FEATURES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_val)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, preds\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/lightgbm/sklearn.py:1284\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1281\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1282\u001b[0m             valid_sets\u001b[38;5;241m.\u001b[39mappend((valid_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform(valid_y)))\n\u001b[0;32m-> 1284\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_class_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_class_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/lightgbm/sklearn.py:955\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    952\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    953\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mbest_iteration\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/lightgbm/engine.py:307\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    296\u001b[0m     cb(\n\u001b[1;32m    297\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[1;32m    298\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m         )\n\u001b[1;32m    305\u001b[0m     )\n\u001b[0;32m--> 307\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
            "File \u001b[0;32m~/Desktop/Github/HSE_hack/.venv/lib/python3.10/site-packages/lightgbm/basic.py:4136\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   4133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   4134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4135\u001b[0m _safe_call(\n\u001b[0;32m-> 4136\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4137\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4139\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4140\u001b[0m )\n\u001b[1;32m   4141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   4142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "if SEARCH_BEST_PARAMS:\n",
        "    lgbm_best_params = study.best_params\n",
        "else:\n",
        "    lgbm_best_params = {\n",
        "        \"boosting_type\": \"dart\",\n",
        "        \"num_leaves\": 80,\n",
        "        \"max_depth\": 8,\n",
        "        \"learning_rate\": 0.02353980066877352,\n",
        "        \"feature_fraction\": 0.7146404372369975,\n",
        "        \"lambda_l1\": 2.9294801014827625,\n",
        "        \"lambda_l2\": 4.301118582479693,\n",
        "        \"min_child_samples\": 85,\n",
        "        \"bagging_fraction\": 0.8207939948373919,\n",
        "        \"bagging_freq\": 3,\n",
        "    }\n",
        "\n",
        "lgbm_best_value, lgbm_best_models = objective(\n",
        "    optuna.trial.FixedTrial(lgbm_best_params),\n",
        "    X_train_lgbm,\n",
        "    y_train,\n",
        "    \"LightGBM\",\n",
        "    return_models=True,\n",
        ")\n",
        "\n",
        "print(f\"Best LightGBM RMSE: {lgbm_best_value}\\n\\n\")\n",
        "print(\"Best LightGBM params:\")\n",
        "print(*[f\"'{key}': {value},\" for key, value in lgbm_best_params.items()], sep=\"\\n\")"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best LightGBM RMSE: 0.8611098264769588\n",
            "\n",
            "\n",
            "Best LightGBM params:\n",
            "'boosting_type': dart,\n",
            "'num_leaves': 80,\n",
            "'max_depth': 8,\n",
            "'learning_rate': 0.02353980066877352,\n",
            "'feature_fraction': 0.7146404372369975,\n",
            "'lambda_l1': 2.9294801014827625,\n",
            "'lambda_l2': 4.301118582479693,\n",
            "'min_child_samples': 85,\n",
            "'bagging_fraction': 0.8207939948373919,\n",
            "'bagging_freq': 3,\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "if SEARCH_BEST_PARAMS:\n",
        "    study = optuna.create_study(\n",
        "        direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
        "    )\n",
        "    study.optimize(\n",
        "        lambda trial: objective(trial, X_train_forest, y_train, \"RandomForest\"),\n",
        "        n_trials=N_TRIALS,\n",
        "        n_jobs=-1,\n",
        "        show_progress_bar=True,\n",
        "    )"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-21 22:34:28,072] A new study created in memory with name: no-name-b3153734-6743-45ee-b44b-751212972ae8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37c7b806df5244c38ff12a0b09df2602",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2024-09-21 22:36:22,785] Trial 8 finished with value: 0.8543033831840481 and parameters: {'n_estimators': 94, 'max_depth': 15, 'min_samples_split': 48, 'min_samples_leaf': 45, 'max_features': 0.08342036906580597}. Best is trial 8 with value: 0.8543033831840481.\n",
            "[I 2024-09-21 22:36:24,813] Trial 9 finished with value: 0.8594489110962236 and parameters: {'n_estimators': 86, 'max_depth': 8, 'min_samples_split': 42, 'min_samples_leaf': 36, 'max_features': 0.5906680603149131}. Best is trial 9 with value: 0.8594489110962236.\n",
            "[I 2024-09-21 22:36:59,678] Trial 3 finished with value: 0.856373796720647 and parameters: {'n_estimators': 160, 'max_depth': 5, 'min_samples_split': 8, 'min_samples_leaf': 35, 'max_features': 0.23902912385045083}. Best is trial 9 with value: 0.8594489110962236.\n",
            "[I 2024-09-21 22:37:34,469] Trial 7 finished with value: 0.8604503664788649 and parameters: {'n_estimators': 185, 'max_depth': 17, 'min_samples_split': 11, 'min_samples_leaf': 44, 'max_features': 0.16164208210938702}. Best is trial 7 with value: 0.8604503664788649.\n",
            "[I 2024-09-21 22:37:51,413] Trial 11 finished with value: 0.8586287551976721 and parameters: {'n_estimators': 177, 'max_depth': 16, 'min_samples_split': 13, 'min_samples_leaf': 12, 'max_features': 0.7980998506289265}. Best is trial 7 with value: 0.8604503664788649.\n",
            "[I 2024-09-21 22:37:52,430] Trial 0 finished with value: 0.8601082458018323 and parameters: {'n_estimators': 186, 'max_depth': 20, 'min_samples_split': 23, 'min_samples_leaf': 28, 'max_features': 0.7931898703650739}. Best is trial 7 with value: 0.8604503664788649.\n",
            "[I 2024-09-21 22:37:52,672] Trial 14 finished with value: 0.8602468003777224 and parameters: {'n_estimators': 231, 'max_depth': 8, 'min_samples_split': 9, 'min_samples_leaf': 16, 'max_features': 0.17729699788985565}. Best is trial 7 with value: 0.8604503664788649.\n",
            "[I 2024-09-21 22:37:55,829] Trial 1 finished with value: 0.8593703733549314 and parameters: {'n_estimators': 200, 'max_depth': 24, 'min_samples_split': 16, 'min_samples_leaf': 15, 'max_features': 0.5883355923492397}. Best is trial 7 with value: 0.8604503664788649.\n",
            "[I 2024-09-21 22:38:47,555] Trial 12 finished with value: 0.861230938370886 and parameters: {'n_estimators': 262, 'max_depth': 27, 'min_samples_split': 9, 'min_samples_leaf': 46, 'max_features': 0.4701993228526824}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:38:49,753] Trial 10 finished with value: 0.847252044222094 and parameters: {'n_estimators': 286, 'max_depth': 24, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 0.032199963949571586}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:38:50,560] Trial 4 finished with value: 0.8553319364890475 and parameters: {'n_estimators': 298, 'max_depth': 17, 'min_samples_split': 17, 'min_samples_leaf': 50, 'max_features': 0.07902172075275438}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:39:26,351] Trial 15 finished with value: 0.8603897386239876 and parameters: {'n_estimators': 318, 'max_depth': 8, 'min_samples_split': 39, 'min_samples_leaf': 12, 'max_features': 0.5771937248905429}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:39:50,292] Trial 23 finished with value: 0.8585843671152105 and parameters: {'n_estimators': 68, 'max_depth': 6, 'min_samples_split': 21, 'min_samples_leaf': 34, 'max_features': 0.4507990331152737}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:40:40,389] Trial 5 finished with value: 0.8607029650326282 and parameters: {'n_estimators': 399, 'max_depth': 19, 'min_samples_split': 11, 'min_samples_leaf': 38, 'max_features': 0.5412171813597507}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:40:54,048] Trial 6 finished with value: 0.8600297040262592 and parameters: {'n_estimators': 407, 'max_depth': 21, 'min_samples_split': 24, 'min_samples_leaf': 24, 'max_features': 0.6024630349544571}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:41:13,275] Trial 13 finished with value: 0.8601367848909479 and parameters: {'n_estimators': 389, 'max_depth': 16, 'min_samples_split': 8, 'min_samples_leaf': 22, 'max_features': 0.7136503475024358}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:41:33,940] Trial 18 finished with value: 0.8603342757757293 and parameters: {'n_estimators': 265, 'max_depth': 31, 'min_samples_split': 43, 'min_samples_leaf': 17, 'max_features': 0.38373824552972335}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:41:36,173] Trial 16 finished with value: 0.8606726537260295 and parameters: {'n_estimators': 319, 'max_depth': 22, 'min_samples_split': 7, 'min_samples_leaf': 19, 'max_features': 0.37546003916153314}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:41:42,495] Trial 24 finished with value: 0.8604473626381715 and parameters: {'n_estimators': 134, 'max_depth': 26, 'min_samples_split': 11, 'min_samples_leaf': 35, 'max_features': 0.7375324402178405}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:41:54,373] Trial 2 finished with value: 0.8609428131699243 and parameters: {'n_estimators': 493, 'max_depth': 24, 'min_samples_split': 18, 'min_samples_leaf': 31, 'max_features': 0.39589977252183783}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:42:12,445] Trial 22 finished with value: 0.8607425587456474 and parameters: {'n_estimators': 320, 'max_depth': 16, 'min_samples_split': 39, 'min_samples_leaf': 37, 'max_features': 0.166793254654251}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:43:01,826] Trial 21 finished with value: 0.8598758432480311 and parameters: {'n_estimators': 356, 'max_depth': 8, 'min_samples_split': 22, 'min_samples_leaf': 30, 'max_features': 0.8709447426905312}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:43:11,677] Trial 17 finished with value: 0.8600665555027728 and parameters: {'n_estimators': 423, 'max_depth': 12, 'min_samples_split': 38, 'min_samples_leaf': 21, 'max_features': 0.9526751565217484}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:43:25,358] Trial 20 finished with value: 0.859516424338121 and parameters: {'n_estimators': 370, 'max_depth': 14, 'min_samples_split': 15, 'min_samples_leaf': 20, 'max_features': 0.8385059380369984}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:43:28,732] Trial 25 finished with value: 0.8609278971059056 and parameters: {'n_estimators': 411, 'max_depth': 32, 'min_samples_split': 28, 'min_samples_leaf': 41, 'max_features': 0.37093116266730775}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:43:39,825] Trial 26 finished with value: 0.8608891871460079 and parameters: {'n_estimators': 418, 'max_depth': 32, 'min_samples_split': 34, 'min_samples_leaf': 41, 'max_features': 0.3682455019915143}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:43:45,440] Trial 19 finished with value: 0.860968911509782 and parameters: {'n_estimators': 498, 'max_depth': 22, 'min_samples_split': 23, 'min_samples_leaf': 40, 'max_features': 0.7717168642954451}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:43:46,373] Trial 28 finished with value: 0.8611826291441685 and parameters: {'n_estimators': 427, 'max_depth': 32, 'min_samples_split': 30, 'min_samples_leaf': 42, 'max_features': 0.35835480822739235}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:43:46,419] Trial 27 finished with value: 0.8609077181494665 and parameters: {'n_estimators': 472, 'max_depth': 32, 'min_samples_split': 30, 'min_samples_leaf': 42, 'max_features': 0.37378794043395347}. Best is trial 12 with value: 0.861230938370886.\n",
            "[I 2024-09-21 22:43:49,835] Trial 29 finished with value: 0.8612870466853071 and parameters: {'n_estimators': 425, 'max_depth': 31, 'min_samples_split': 33, 'min_samples_leaf': 44, 'max_features': 0.38331686104122775}. Best is trial 29 with value: 0.8612870466853071.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# \u0412\u044b\u0432\u043e\u0434 \u043b\u0443\u0447\u0448\u0438\u0445 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u0438 \u043c\u0435\u0442\u0440\u0438\u043a\n",
        "if SEARCH_BEST_PARAMS:\n",
        "    rf_best_params = study.best_params\n",
        "else:\n",
        "    rf_best_params = {\n",
        "        \"n_estimators\": 425,\n",
        "        \"max_depth\": 31,\n",
        "        \"min_samples_split\": 33,\n",
        "        \"min_samples_leaf\": 44,\n",
        "        \"max_features\": 0.38331686104122775,\n",
        "    }\n",
        "\n",
        "rf_best_value, rf_best_models = objective(\n",
        "    optuna.trial.FixedTrial(rf_best_params),\n",
        "    X_train_forest,\n",
        "    y_train,\n",
        "    \"RandomForest\",\n",
        "    return_models=True,\n",
        ")\n",
        "\n",
        "print(f\"Best Random Forest RMSE: {rf_best_value}\\n\\n\")\n",
        "print(\"Best Random Forest params:\")\n",
        "print(*[f\"'{key}': {value},\" for key, value in rf_best_params.items()], sep=\"\\n\")"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Random Forest RMSE: 0.8612870466853071\n",
            "\n",
            "\n",
            "Best Random Forest params:\n",
            "'n_estimators': 425,\n",
            "'max_depth': 31,\n",
            "'min_samples_split': 33,\n",
            "'min_samples_leaf': 44,\n",
            "'max_features': 0.38331686104122775,\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "if SEARCH_BEST_PARAMS:\n",
        "    study = optuna.create_study(\n",
        "        direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=RANDOM_SEED)\n",
        "    )\n",
        "    study.optimize(\n",
        "        lambda trial: objective(trial, X_train_forest, y_train, \"ExtraTrees\"),\n",
        "        n_trials=N_TRIALS - 15,\n",
        "        n_jobs=1,\n",
        "        show_progress_bar=True,\n",
        "    )"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-21 22:44:54,418] A new study created in memory with name: no-name-a75b9a82-c594-402a-a038-c6cc79c6c16f\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d699da6cb07e462eb4b2636fc03723b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/15 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[I 2024-09-21 22:44:59,396] Trial 0 finished with value: 0.8551317486861899 and parameters: {'n_estimators': 218, 'max_depth': 31, 'min_samples_split': 37, 'min_samples_leaf': 30, 'max_features': 0.15601864044243652}. Best is trial 0 with value: 0.8551317486861899.\n",
            "[I 2024-09-21 22:45:01,395] Trial 1 finished with value: 0.846770334777635 and parameters: {'n_estimators': 120, 'max_depth': 3, 'min_samples_split': 44, 'min_samples_leaf': 31, 'max_features': 0.7080725777960455}. Best is trial 0 with value: 0.8551317486861899.\n",
            "[I 2024-09-21 22:45:03,062] Trial 2 finished with value: 0.8585579156835859 and parameters: {'n_estimators': 59, 'max_depth': 32, 'min_samples_split': 42, 'min_samples_leaf': 11, 'max_features': 0.18182496720710062}. Best is trial 2 with value: 0.8585579156835859.\n",
            "[I 2024-09-21 22:45:06,712] Trial 3 finished with value: 0.8599164836062212 and parameters: {'n_estimators': 132, 'max_depth': 11, 'min_samples_split': 27, 'min_samples_leaf': 22, 'max_features': 0.2912291401980419}. Best is trial 3 with value: 0.8599164836062212.\n",
            "[I 2024-09-21 22:45:13,100] Trial 4 finished with value: 0.8544093571137644 and parameters: {'n_estimators': 325, 'max_depth': 6, 'min_samples_split': 16, 'min_samples_leaf': 19, 'max_features': 0.45606998421703593}. Best is trial 3 with value: 0.8599164836062212.\n",
            "[I 2024-09-21 22:45:16,774] Trial 5 finished with value: 0.8247799970099619 and parameters: {'n_estimators': 404, 'max_depth': 8, 'min_samples_split': 27, 'min_samples_leaf': 30, 'max_features': 0.046450412719997725}. Best is trial 3 with value: 0.8599164836062212.\n",
            "[I 2024-09-21 22:45:29,996] Trial 6 finished with value: 0.8584741371013029 and parameters: {'n_estimators': 324, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 48, 'max_features': 0.9656320330745594}. Best is trial 3 with value: 0.8599164836062212.\n",
            "[I 2024-09-21 22:45:43,206] Trial 7 finished with value: 0.860252457598218 and parameters: {'n_estimators': 414, 'max_depth': 11, 'min_samples_split': 6, 'min_samples_leaf': 35, 'max_features': 0.4401524937396013}. Best is trial 7 with value: 0.860252457598218.\n",
            "[I 2024-09-21 22:45:46,100] Trial 8 finished with value: 0.857771358182689 and parameters: {'n_estimators': 105, 'max_depth': 17, 'min_samples_split': 3, 'min_samples_leaf': 46, 'max_features': 0.2587799816000169}. Best is trial 7 with value: 0.860252457598218.\n",
            "[I 2024-09-21 22:45:52,667] Trial 9 finished with value: 0.8563620205139746 and parameters: {'n_estimators': 348, 'max_depth': 11, 'min_samples_split': 27, 'min_samples_leaf': 28, 'max_features': 0.18485445552552704}. Best is trial 7 with value: 0.860252457598218.\n",
            "[I 2024-09-21 22:46:27,650] Trial 10 finished with value: 0.8551312305553204 and parameters: {'n_estimators': 490, 'max_depth': 23, 'min_samples_split': 14, 'min_samples_leaf': 1, 'max_features': 0.6400885024675562}. Best is trial 7 with value: 0.860252457598218.\n",
            "[I 2024-09-21 22:46:34,800] Trial 11 finished with value: 0.8597797719103643 and parameters: {'n_estimators': 205, 'max_depth': 15, 'min_samples_split': 17, 'min_samples_leaf': 40, 'max_features': 0.37960424342022336}. Best is trial 7 with value: 0.860252457598218.\n",
            "[I 2024-09-21 22:46:59,346] Trial 12 finished with value: 0.8608913874445427 and parameters: {'n_estimators': 497, 'max_depth': 13, 'min_samples_split': 33, 'min_samples_leaf': 17, 'max_features': 0.5950385565501397}. Best is trial 12 with value: 0.8608913874445427.\n",
            "[I 2024-09-21 22:47:28,767] Trial 13 finished with value: 0.8596898871702408 and parameters: {'n_estimators': 487, 'max_depth': 22, 'min_samples_split': 34, 'min_samples_leaf': 14, 'max_features': 0.6263510221562969}. Best is trial 12 with value: 0.8608913874445427.\n",
            "[I 2024-09-21 22:47:54,579] Trial 14 finished with value: 0.8598734229127756 and parameters: {'n_estimators': 422, 'max_depth': 13, 'min_samples_split': 50, 'min_samples_leaf': 38, 'max_features': 0.8052519186638233}. Best is trial 12 with value: 0.8608913874445427.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "# \u0412\u044b\u0432\u043e\u0434 \u043b\u0443\u0447\u0448\u0438\u0445 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432 \u0438 \u043c\u0435\u0442\u0440\u0438\u043a\n",
        "if SEARCH_BEST_PARAMS:\n",
        "    et_best_params = study.best_params\n",
        "else:\n",
        "    et_best_params = {\n",
        "        \"n_estimators\": 497,\n",
        "        \"max_depth\": 13,\n",
        "        \"min_samples_split\": 33,\n",
        "        \"min_samples_leaf\": 17,\n",
        "        \"max_features\": 0.5950385565501397,\n",
        "    }\n",
        "\n",
        "et_best_value, et_best_models = objective(\n",
        "    optuna.trial.FixedTrial(et_best_params),\n",
        "    X_train_forest,\n",
        "    y_train,\n",
        "    \"ExtraTrees\",\n",
        "    return_models=True,\n",
        ")\n",
        "\n",
        "print(f\"Best Extra Trees RMSE: {et_best_value}\\n\\n\")\n",
        "print(\"Best Extra Trees params:\")\n",
        "print(*[f\"'{key}': {value},\" for key, value in et_best_params.items()], sep=\"\\n\")"
      ],
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Extra Trees RMSE: 0.8608913874445427\n",
            "\n",
            "\n",
            "Best Extra Trees params:\n",
            "'n_estimators': 497,\n",
            "'max_depth': 13,\n",
            "'min_samples_split': 33,\n",
            "'min_samples_leaf': 17,\n",
            "'max_features': 0.5950385565501397,\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "catboost_y_pred = np.zeros(df_test.shape[0])\n",
        "\n",
        "for model in models_list:\n",
        "    catboost_y_pred += model.predict_proba(df_test)[:, 1]\n",
        "catboost_y_pred = catboost_y_pred / len(models_list)\n",
        "\n",
        "lgbm_y_pred = np.zeros(df_test_lgbm.shape[0])\n",
        "\n",
        "for model in lgbm_best_models:\n",
        "    lgbm_y_pred += model.predict_proba(df_test_lgbm)[:, 1]\n",
        "lgbm_y_pred = lgbm_y_pred / len(models_list)\n",
        "\n",
        "\n",
        "rf_y_pred = np.zeros(df_test_forest.shape[0])\n",
        "\n",
        "for model in rf_best_models:\n",
        "    rf_y_pred += model.predict_proba(df_test_forest)[:, 1]\n",
        "rf_y_pred = rf_y_pred / len(models_list)\n",
        "\n",
        "\n",
        "et_y_pred = np.zeros(df_test_forest.shape[0])\n",
        "\n",
        "for model in et_best_models:\n",
        "    et_y_pred += model.predict_proba(df_test_forest)[:, 1]\n",
        "et_y_pred = et_y_pred / len(models_list)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "final = np.zeros(df_test.shape[0])\n",
        "\n",
        "final += catboost_y_pred + lgbm_y_pred + rf_y_pred + et_y_pred\n",
        "final = final / 4"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [
        "submissiom = pd.DataFrame(final)\n",
        "submissiom.to_csv(\"4x_blending.csv\", index=False, header=False)"
      ],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {},
      "source": [],
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    }
  ]
}
